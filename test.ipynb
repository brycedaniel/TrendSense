{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.49)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.54-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2024.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (3.17.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Downloading yfinance-0.2.54-py2.py3-none-any.whl (108 kB)\n",
      "Installing collected packages: yfinance\n",
      "  Attempting uninstall: yfinance\n",
      "    Found existing installation: yfinance 0.2.49\n",
      "    Uninstalling yfinance-0.2.49:\n",
      "      Successfully uninstalled yfinance-0.2.49\n",
      "Successfully installed yfinance-0.2.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import functions_framework\n",
    "from flask import jsonify\n",
    "import logging\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "gcloud functions deploy step-3-p-1 --runtime python311 --trigger-http --allow-unauthenticated --region=us-central1 --entry-point process_data\n",
    "# Define source and target BigQuery tables\n",
    "SOURCE_TABLE = 'trendsense.combined_data.step_3_predictive_1'\n",
    "STOCK_HISTORY_TABLE = 'trendsense.stock_data.stock_data_history'\n",
    "TARGET_TABLE = 'trendsense.combined_data.step_4_final'\n",
    "REGRESSION_TABLE = 'trendsense.combined_data.step_4_test_train'\n",
    "\n",
    "@functions_framework.http\n",
    "def process_stock_data(request):\n",
    "    try:\n",
    "        logging.info(\"Starting data processing...\")\n",
    "        \n",
    "        # First, get the regression coefficients\n",
    "        regression_query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM `{REGRESSION_TABLE}`\n",
    "        \"\"\"\n",
    "        regression_df = client.query(regression_query).to_dataframe()\n",
    "        \n",
    "        # Create a dictionary of regression coefficients for quick lookup\n",
    "        regression_dict = {\n",
    "            row['Ticker']: {\n",
    "                'intercept': row['Intercept'],\n",
    "                'ai_coef': row['AI_Coefficient'],\n",
    "                'sentiment_coef': row['Sentiment_Coefficient'],\n",
    "                'health_coef': row['Health_Coefficient']\n",
    "            }\n",
    "            for _, row in regression_df.iterrows()\n",
    "        }\n",
    "\n",
    "        # Modified query to use FULL OUTER JOIN\n",
    "        query = f\"\"\"\n",
    "      WITH stock_history AS (\n",
    "  SELECT DISTINCT\n",
    "    Ticker,\n",
    "    DATE(Date) as Date,\n",
    "    Close,\n",
    "    Percent_Difference,\n",
    "    LEAD(Percent_Difference) OVER (PARTITION BY Ticker ORDER BY Date) as Next_Day_Percent\n",
    "  FROM `trendsense.stock_data.stock_data_history`\n",
    "  WHERE ticker != 'GSAT'\n",
    "),\n",
    "\n",
    "predictive_data AS (\n",
    "  SELECT\n",
    "    ticker,\n",
    "    DATE(date) as date,\n",
    "    Stock_Category,\n",
    "    Aggregated_Score,\n",
    "    AI_Score,\n",
    "    `Sentiment Score` as Sentiment_Score,\n",
    "    Health_Score\n",
    "  FROM `trendsense.combined_data.step_3_predictive_1`\n",
    "  WHERE Ticker != 'GSAT'\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  COALESCE(sh.Date, pd.date) as date,\n",
    "  COALESCE(sh.Ticker, pd.ticker) as ticker,\n",
    "  COALESCE(pd.Stock_Category, 'Unknown') as Stock_Category,\n",
    "  pd.Aggregated_Score,\n",
    "  pd.AI_Score,\n",
    "  pd.Sentiment_Score as `Sentiment Score`,\n",
    "  pd.Health_Score,\n",
    "  sh.Close,\n",
    "  sh.Percent_Difference as Avg_Daily_Percent_Difference,\n",
    "  sh.Next_Day_Percent as Avg_Next_Daily_Percent_Difference\n",
    "FROM (\n",
    "  SELECT * FROM stock_history \n",
    "  UNION ALL\n",
    "  SELECT DISTINCT ticker, date, NULL as Close, NULL as Percent_Difference, NULL as Next_Day_Percent \n",
    "  FROM predictive_data \n",
    "  WHERE date NOT IN (SELECT DISTINCT Date FROM stock_history)\n",
    ") sh\n",
    "FULL OUTER JOIN predictive_data pd\n",
    "ON LOWER(sh.Ticker) = LOWER(pd.ticker)\n",
    "AND sh.Date = pd.date\n",
    "ORDER BY\n",
    "  COALESCE(sh.Date, pd.date),\n",
    "  COALESCE(sh.Ticker, pd.ticker)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Rest of the function remains the same\n",
    "        query_job = client.query(query)\n",
    "        df = query_job.to_dataframe()\n",
    "\n",
    "        filter_date = pd.to_datetime('2024-12-1')\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df[df['date'] >= filter_date]\n",
    "        df = df.sort_values(['ticker', 'date'])\n",
    "      \n",
    "\n",
    "        \n",
    "        # Additional filter for GSAT just in case\n",
    "        df = df[df['ticker'] != 'GSAT']\n",
    "\n",
    "        df_grouped = df.groupby(['ticker', 'date', 'Stock_Category']).agg({\n",
    "            'Aggregated_Score': 'mean',\n",
    "            'Close': 'last',\n",
    "            'Avg_Daily_Percent_Difference': 'mean',\n",
    "            'Avg_Next_Daily_Percent_Difference': 'mean',\n",
    "            'AI_Score': 'mean',\n",
    "            'Sentiment Score': 'mean',\n",
    "            'Health_Score': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        # Updated column renaming\n",
    "        df_grouped = df_grouped.rename(columns={\n",
    "            'Aggregated_Score': 'TS_Score',\n",
    "            'Avg_Daily_Percent_Difference': 'Price_Movement_Today',\n",
    "            'Avg_Next_Daily_Percent_Difference': 'Price_Movement_Tomorrow',\n",
    "            'AI_Score': 'AI_Score',\n",
    "            'Sentiment Score': 'Sentiment_Score',\n",
    "            'Health_Score': 'Health_Score'\n",
    "        })\n",
    "        # Convert 'date' in df_grouped to datetime (now it exists)\n",
    "        df_grouped['date'] = pd.to_datetime(df_grouped['date'], errors='coerce')\n",
    "\n",
    "        # Compute Week_of_Year with Saturday-Friday weeks\n",
    "        df_grouped['Week_of_Year'] = (df_grouped['date'] - pd.Timedelta(days=-2)).dt.isocalendar().week\n",
    "        # Calculate predicted next day percentage\n",
    "        def predict_next_day(row):\n",
    "            ticker_coef = regression_dict.get(row['ticker'])\n",
    "            if ticker_coef:\n",
    "                prediction = (\n",
    "                    ticker_coef['intercept'] +\n",
    "                    ticker_coef['ai_coef'] * row['AI_Score'] +\n",
    "                    ticker_coef['sentiment_coef'] * row['Sentiment_Score'] +\n",
    "                    ticker_coef['health_coef'] * row['Health_Score']\n",
    "                )\n",
    "                # Clip predictions to reasonable bounds\n",
    "                return max(min(prediction, 0.05), -0.05)\n",
    "            return None\n",
    "\n",
    "        df_grouped['Predicted_Price_Movement'] = df_grouped.apply(predict_next_day, axis=1)\n",
    "\n",
    "        # Continue with existing calculations\n",
    "        df_grouped['Price_Movement_Today'] = df_grouped['Price_Movement_Today'].fillna(0)\n",
    "        \n",
    "        def calculate_4week_avg(group):\n",
    "            \"\"\"Calculate the average TS_Score for the last 4 weeks per ticker, excluding the current week.\"\"\"\n",
    "            group = group.sort_values(by=\"Week_of_Year\")  # Ensure correct order\n",
    "\n",
    "            def last_4_week_avg(row):\n",
    "                last_4_weeks = group[\n",
    "                    (group['Week_of_Year'] < row['Week_of_Year']) &  # Exclude current week\n",
    "                    (group['Week_of_Year'] >= row['Week_of_Year'] - 4)  # Include only last 4 weeks\n",
    "                ]\n",
    "                return last_4_weeks['TS_Score'].mean() if not last_4_weeks.empty else None\n",
    "\n",
    "            group['TS_Score_4Week'] = group.apply(last_4_week_avg, axis=1)\n",
    "\n",
    "            return group\n",
    "\n",
    "        # Apply function grouped by ticker\n",
    "        df_grouped = df_grouped.groupby('ticker', group_keys=False).apply(calculate_4week_avg)\n",
    "\n",
    "        # Rank stocks based on the 4-week average (higher average = better rank)\n",
    "        df_grouped['TS_Rank_4Week'] = df_grouped.groupby('date')['TS_Score_4Week'].rank(\n",
    "            method='min',\n",
    "            ascending=False  # Higher scores get better ranks\n",
    "        )\n",
    "\n",
    "     \n",
    "        # Calculate week-over-week change (last Friday vs previous Friday)\n",
    "        def calculate_friday_change(group):\n",
    "            # Get the last date in the data\n",
    "            last_date = group['date'].max()\n",
    "            \n",
    "            # Find the last Friday\n",
    "            days_to_friday = (last_date.dayofweek - 4) % 7\n",
    "            last_friday = last_date - pd.Timedelta(days=days_to_friday)\n",
    "            \n",
    "            # Find the previous Friday\n",
    "            prev_friday = last_friday - pd.Timedelta(weeks=1)\n",
    "            \n",
    "            # Get scores for these dates\n",
    "            last_friday_score = group[group['date'] == last_friday]['TS_Score'].iloc[0] if len(group[group['date'] == last_friday]) > 0 else None\n",
    "            prev_friday_score = group[group['date'] == prev_friday]['TS_Score'].iloc[0] if len(group[group['date'] == prev_friday]) > 0 else None\n",
    "            \n",
    "            if last_friday_score is not None and prev_friday_score is not None:\n",
    "                pct_change = ((last_friday_score - prev_friday_score) / prev_friday_score) * 100\n",
    "            else:\n",
    "                pct_change = 0\n",
    "                \n",
    "            # Apply the change to all rows\n",
    "            return pd.Series(pct_change, index=group.index)\n",
    "\n",
    "        # Calculate and rank the Friday-to-Friday change\n",
    "        df_grouped['TS_Friday_Change'] = df_grouped.groupby('ticker').apply(\n",
    "            calculate_friday_change\n",
    "        ).reset_index(level=0, drop=True)\n",
    "\n",
    "        df_grouped['TS_Rank_Friday_Change'] = df_grouped.groupby('date')['TS_Friday_Change'].rank(\n",
    "            method='min',\n",
    "            ascending=False  # Higher change gets better ranks (lower numbers)\n",
    "        )\n",
    "\n",
    "        # Calculate 4-week composite score (average of both ranks)\n",
    "        df_grouped['Composite_Rank_4Week'] = (df_grouped['TS_Rank_4Week'] + df_grouped['TS_Rank_Friday_Change']) / 2\n",
    "        \n",
    "        #####################################################\n",
    "        # Get the most recent Composite_Rank_4Week for each ticker in each week\n",
    "        latest_rank = (\n",
    "            df_grouped.groupby(['Week_of_Year', 'ticker'])['Composite_Rank_4Week']\n",
    "            .last()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Calculate the sum of Price_Movement_Today for each ticker within each week\n",
    "        weekly_ticker_sums = (\n",
    "            df_grouped.groupby(['Week_of_Year', 'ticker'])['Price_Movement_Today']\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Merge to get Composite Rank per ticker per week\n",
    "        weekly_ticker_analysis = weekly_ticker_sums.merge(\n",
    "            latest_rank, \n",
    "            on=['Week_of_Year', 'ticker']\n",
    "        )\n",
    "\n",
    "        # Get the top 10 tickers based on Composite_Rank_4Week and their individual sums\n",
    "        weekly_top_10_sums = (\n",
    "            weekly_ticker_analysis.groupby('Week_of_Year')\n",
    "            .apply(lambda x: x.nsmallest(10, 'Composite_Rank_4Week'))\n",
    "            .reset_index(drop=True)\n",
    "            .rename(columns={'Price_Movement_Today': 'Weekly_Ticker_Movement'})\n",
    "        )\n",
    "\n",
    "        # Calculate the average movement for top 10 tickers per week\n",
    "        weekly_averages = (\n",
    "            weekly_top_10_sums.groupby('Week_of_Year')['Weekly_Ticker_Movement']\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .rename(columns={'Weekly_Ticker_Movement': 'Weekly_Ticker_Avg_Movement'})\n",
    "        )\n",
    "\n",
    "        # Merge the individual ticker movements and weekly averages back to the main dataframe\n",
    "        df_grouped = df_grouped.merge(\n",
    "            weekly_top_10_sums[['Week_of_Year', 'ticker', 'Weekly_Ticker_Movement']],\n",
    "            on=['Week_of_Year', 'ticker'],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        df_grouped = df_grouped.merge(\n",
    "            weekly_averages,\n",
    "            on='Week_of_Year',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Fill NaN values with 0\n",
    "        df_grouped['Weekly_Ticker_Movement'] = df_grouped['Weekly_Ticker_Movement'].fillna(0)\n",
    "        df_grouped['Weekly_Ticker_Avg_Movement'] = df_grouped['Weekly_Ticker_Avg_Movement'].fillna(0)\n",
    "\n",
    "        # Compute weekly cumulative sum for 2025 weeks based on average movement\n",
    "        weekly_2025_returns = (\n",
    "            df_grouped[df_grouped['date'] >= '2025-01-01']\n",
    "            .groupby('Week_of_Year')['Weekly_Ticker_Avg_Movement']\n",
    "            .first()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Calculate cumulative sum of the averages\n",
    "        weekly_2025_returns['Weekly_Ticker_Cumulative'] = weekly_2025_returns['Weekly_Ticker_Avg_Movement'].cumsum()\n",
    "\n",
    "        # Merge back to main dataframe\n",
    "        df_grouped = df_grouped.merge(\n",
    "            weekly_2025_returns[['Week_of_Year', 'Weekly_Ticker_Cumulative']],\n",
    "            on='Week_of_Year',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # Fill NaN values with 0 for pre-2025 dates\n",
    "        df_grouped['Weekly_Ticker_Cumulative'] = df_grouped.apply(\n",
    "            lambda row: row['Weekly_Ticker_Cumulative'] if row['date'].year >= 2025 else 0,\n",
    "            axis=1\n",
    "        )\n",
    "        ########################################################\n",
    "        df_grouped['TS_Score_7'] = df_grouped.groupby('ticker')['TS_Score'].transform(\n",
    "            lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    "        )\n",
    "\n",
    "        df_grouped['TS_Rank_7'] = df_grouped.groupby('date')['TS_Score_7'].rank(\n",
    "            method='min',\n",
    "            ascending=False\n",
    "        )\n",
    "\n",
    "        df_grouped['TS_Change'] = df_grouped.groupby('ticker')['TS_Score'].pct_change() * 100\n",
    "        df_grouped['TS_Rank_Change'] = df_grouped.groupby('date')['TS_Change'].rank(\n",
    "            method='min',\n",
    "            ascending=False\n",
    "        )\n",
    "\n",
    "        df_grouped['Composite_Rank'] = (df_grouped['TS_Rank_7'] + df_grouped['TS_Rank_Change']) / 2\n",
    "        \n",
    "        # Calculate daily top 10 averages with new column names\n",
    "       \n",
    "       \n",
    "        daily_top_10_avg_next = (\n",
    "            df_grouped.groupby('date')\n",
    "            .apply(lambda x: x.nsmallest(10, 'Composite_Rank')['Price_Movement_Tomorrow'].mean())\n",
    "            .reset_index()\n",
    "            .rename(columns={0: 'Top_10_Composite_Price_Movement_Tomorrow'})\n",
    "        )\n",
    "        \n",
    "        # Fill NaN values with 0 for Top_10_Composite_Price_Movement_Tomorrow\n",
    "        daily_top_10_avg_next['Top_10_Composite_Price_Movement_Tomorrow'] = (\n",
    "            daily_top_10_avg_next['Top_10_Composite_Price_Movement_Tomorrow'].fillna(0)\n",
    "        )\n",
    "\n",
    "        daily_top_10_avg_today = (\n",
    "            df_grouped.groupby('date')\n",
    "            .apply(lambda x: x.nsmallest(10, 'Composite_Rank')['Price_Movement_Today'].mean())\n",
    "            .reset_index()\n",
    "            .rename(columns={0: 'Top_10_Composite_Price_Movement_Today'})\n",
    "        )\n",
    "\n",
    "        daily_top_10_predicted = (\n",
    "            df_grouped.groupby('date')\n",
    "            .apply(lambda x: x.nsmallest(10, 'Composite_Rank')['Predicted_Price_Movement'].mean())\n",
    "            .reset_index()\n",
    "            .rename(columns={0: 'Top_10_Predicted_Price_Movement'})\n",
    "        )\n",
    "\n",
    "        # Merge the daily averages back\n",
    "        df_grouped = df_grouped.merge(daily_top_10_avg_next, on='date', how='left')\n",
    "        df_grouped = df_grouped.merge(daily_top_10_avg_today, on='date', how='left')\n",
    "        df_grouped = df_grouped.merge(daily_top_10_predicted, on='date', how='left')\n",
    "\n",
    "        # Calculate cumulative sums for 2025\n",
    "        df_2025 = df_grouped[df_grouped['date'] >= '2025-01-01'].copy()\n",
    "\n",
    "        daily_cumulative_next = (\n",
    "            df_2025.groupby('date')['Top_10_Composite_Price_Movement_Tomorrow']\n",
    "            .mean()\n",
    "            .cumsum()\n",
    "            .reset_index()\n",
    "            .rename(columns={'Top_10_Composite_Price_Movement_Tomorrow': 'Top_10_YTD_Cumulative_Tomorrow'})\n",
    "        )\n",
    "\n",
    "        daily_cumulative_today = (\n",
    "            df_2025.groupby('date')['Top_10_Composite_Price_Movement_Today']\n",
    "            .mean()\n",
    "            .cumsum()\n",
    "            .reset_index()\n",
    "            .rename(columns={'Top_10_Composite_Price_Movement_Today': 'Top_10_YTD_Cumulative_Today'})\n",
    "        )\n",
    "\n",
    "        daily_cumulative_predicted = (\n",
    "            df_2025.groupby('date')['Top_10_Predicted_Price_Movement']\n",
    "            .mean()\n",
    "            .cumsum()\n",
    "            .reset_index()\n",
    "            .rename(columns={'Top_10_Predicted_Price_Movement': 'Top_10_YTD_Cumulative_Predicted'})\n",
    "        )\n",
    "\n",
    "        # Merge cumulative sums\n",
    "        df_grouped = df_grouped.merge(daily_cumulative_next, on='date', how='left')\n",
    "        df_grouped = df_grouped.merge(daily_cumulative_today, on='date', how='left')\n",
    "        df_grouped = df_grouped.merge(daily_cumulative_predicted, on='date', how='left')\n",
    "\n",
    "        # Fill missing cumulative scores\n",
    "        df_grouped['Top_10_YTD_Cumulative_Tomorrow'].fillna(0, inplace=True)\n",
    "        df_grouped['Top_10_YTD_Cumulative_Today'].fillna(0, inplace=True)\n",
    "        df_grouped['Top_10_YTD_Cumulative_Predicted'].fillna(0, inplace=True)\n",
    "\n",
    "        # Final sort\n",
    "        df_grouped = df_grouped.sort_values(['date'])\n",
    "\n",
    "        # Save to BigQuery (overwrite existing table)\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "            autodetect=True\n",
    "        )\n",
    "\n",
    "        job = client.load_table_from_dataframe(df_grouped, TARGET_TABLE, job_config=job_config)\n",
    "        job.result()\n",
    "\n",
    "        return jsonify({\n",
    "            \"message\": f\"Data successfully overwritten in {TARGET_TABLE}\",\n",
    "            \"row_count\": len(df_grouped)\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in processing: {str(e)}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetching stock data from 2025-02-10 to 2025-02-13\n",
      "INFO:__main__:Fetching NASDAQ (^IXIC) and S&P 500 (^GSPC) data from 2025-02-10 to 2025-02-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  37 of 37 completed\n",
      "[*********************100%***********************]  2 of 2 completed\n",
      "INFO:__main__:Stock data saved locally as stock_data_2025-02-13.csv\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define stock tickers\n",
    "TICKERS = [\n",
    "    'AAPL', 'GOOGL', 'MSFT', 'ASTS', 'PTON', 'GSAT', 'PLTR', 'SMR', 'ACHR',\n",
    "    'BWXT', 'ARBK', 'AMD', 'NVDA', 'GME', 'MU', 'TSLA', 'NFLX', 'ZG',\n",
    "    'AVGO', 'SMCI', 'GLW', 'HAL', 'LMT', 'AMZN', 'CRM', 'NOW', 'CHTR', 'TDS', 'META', 'RGTI', 'QUBT',\n",
    "    'LX', 'OKLO', 'PSIX', 'QFIN', 'RTX', 'TWLO'\n",
    "]\n",
    "\n",
    "# Market Index Tickers\n",
    "INDEX_TICKERS = [\"^IXIC\", \"^GSPC\"]  # NASDAQ and S&P 500\n",
    "\n",
    "def extract_stock_close():\n",
    "    \"\"\"Fetch stock data and save it locally as a CSV file.\"\"\"\n",
    "    try:\n",
    "        today = datetime.today().date()\n",
    "        start_date = today - timedelta(days=3)\n",
    "        \n",
    "        logger.info(f\"Fetching stock data from {start_date} to {today}\")\n",
    "        logger.info(f\"Fetching NASDAQ (^IXIC) and S&P 500 (^GSPC) data from {start_date} to {today}\")\n",
    "\n",
    "        # Fetch stock data\n",
    "        try:\n",
    "            stock_data = yf.download(TICKERS, start=start_date, end=today, group_by='ticker', threads=5)\n",
    "        except Exception as download_error:\n",
    "            logger.error(f\"Failed to download stock data: {download_error}\")\n",
    "            return\n",
    "\n",
    "        # Fetch NASDAQ and S&P 500 data\n",
    "        try:\n",
    "            index_data = yf.download(INDEX_TICKERS, start=start_date, end=today, group_by='ticker')\n",
    "        except Exception as index_error:\n",
    "            logger.error(f\"Failed to download index data: {index_error}\")\n",
    "            return\n",
    "\n",
    "        formatted_data = []\n",
    "\n",
    "        # Process normal tickers using Yahoo Finance dates\n",
    "        for ticker in TICKERS:\n",
    "            try:\n",
    "                if ticker in stock_data.columns.get_level_values(0):\n",
    "                    ticker_data = stock_data[ticker].reset_index()  # Convert index to column\n",
    "\n",
    "                    for _, row in ticker_data.iterrows():\n",
    "                        if pd.notna(row['Close']):\n",
    "                            previous_close = ticker_data['Close'].shift(1).iloc[_] if _ > 0 else None\n",
    "                            percent_difference = ((row['Close'] - previous_close) / previous_close) if previous_close else None\n",
    "\n",
    "                            formatted_data.append({\n",
    "                                \"Date\": row[\"Date\"].strftime('%Y-%m-%d'),\n",
    "                                \"Ticker\": ticker,\n",
    "                                \"Close\": row['Close'],\n",
    "                                \"Volume\": row['Volume'],\n",
    "                                \"High\": row['High'],\n",
    "                                \"Low\": row['Low'],\n",
    "                                \"Open\": row['Open'],\n",
    "                                \"Percent_Difference\": percent_difference\n",
    "                            })\n",
    "            except Exception as ticker_error:\n",
    "                logger.error(f\"Error processing {ticker}: {ticker_error}\")\n",
    "                continue\n",
    "\n",
    "        # Process NASDAQ and S&P 500 Data\n",
    "        for ticker in INDEX_TICKERS:\n",
    "            if ticker in index_data.columns.get_level_values(0):\n",
    "                index_df = index_data[ticker].reset_index()  # Convert index to column\n",
    "                \n",
    "                for _, row in index_df.iterrows():\n",
    "                    try:\n",
    "                        previous_close = index_df[\"Close\"].shift(1).iloc[_] if _ > 0 else None\n",
    "                        percent_difference = ((row[\"Close\"] - previous_close) / previous_close) if previous_close else None\n",
    "\n",
    "                        formatted_data.append({\n",
    "                            \"Date\": row[\"Date\"].strftime('%Y-%m-%d'),\n",
    "                            \"Ticker\": ticker,\n",
    "                            \"Close\": row[\"Close\"],\n",
    "                            \"Volume\": row[\"Volume\"] if \"Volume\" in index_df.columns else None,\n",
    "                            \"High\": row[\"High\"] if \"High\" in index_df.columns else None,\n",
    "                            \"Low\": row[\"Low\"] if \"Low\" in index_df.columns else None,\n",
    "                            \"Open\": row[\"Open\"] if \"Open\" in index_df.columns else None,\n",
    "                            \"Percent_Difference\": percent_difference\n",
    "                        })\n",
    "                    except Exception as index_error:\n",
    "                        logger.error(f\"Error processing {ticker}: {index_error}\")\n",
    "                        continue\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        reformatted_data = pd.DataFrame(formatted_data)\n",
    "\n",
    "        if reformatted_data.empty:\n",
    "            logger.warning(f\"No valid stock data available for {today}\")\n",
    "            return\n",
    "\n",
    "        # Save to CSV file locally\n",
    "        file_path = f\"stock_data_{today}.csv\"\n",
    "        reformatted_data.to_csv(file_path, index=False)\n",
    "        \n",
    "        logger.info(f\"Stock data saved locally as {file_path}\")\n",
    "\n",
    "    except Exception as general_error:\n",
    "        logger.error(f\"Unexpected error in extract_stock_close: {general_error}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_stock_close()\n",
    "\n",
    "\n",
    "\n",
    "  # Add 4-week Friday-to-Friday average calculation\n",
    "        df_grouped['is_friday'] = df_grouped['date'].dt.day_name() == 'Friday'\n",
    "\n",
    "  def calculate_friday_4week_avg(group):\n",
    "            friday_data = group[group['is_friday']].copy()\n",
    "            if friday_data.empty:\n",
    "                return pd.Series(index=group.index, dtype='float64')\n",
    "            \n",
    "            friday_averages = friday_data['TS_Score'].rolling(window=4, min_periods=1).mean()\n",
    "            friday_data['TS_Score_4Week'] = friday_averages\n",
    "            \n",
    "            result = friday_data['TS_Score_4Week'].reindex(group.index).ffill()\n",
    "            return result\n",
    "\n",
    "        df_grouped['TS_Score_4Week'] = df_grouped.groupby('ticker').apply(\n",
    "            calculate_friday_4week_avg\n",
    "        ).reset_index(level=0, drop=True)\n",
    "\n",
    "        # Drop the helper column as it's no longer needed\n",
    "        df_grouped = df_grouped.drop('is_friday', axis=1)\n",
    "        \n",
    "         # Rank stocks based on 4-week average (higher average = better rank)\n",
    "        df_grouped['TS_Rank_4Week'] = df_grouped.groupby('date')['TS_Score_4Week'].rank(\n",
    "            method='min',\n",
    "            ascending=False  # Higher scores get better ranks (lower numbers)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from google.cloud import bigquery\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define BigQuery dataset and table\n",
    "PROJECT_ID = \"trendsense\"\n",
    "DATASET_ID = \"stock_data\"\n",
    "TABLE_ID = \"stock_data_history\"\n",
    "\n",
    "# Define the list of stock tickers\n",
    "TICKERS = [\n",
    "    'AAPL', 'GOOGL', 'MSFT', 'ASTS', 'PTON', 'GSAT', 'PLTR', 'SMR', 'ACHR',\n",
    "    'BWXT', 'ARBK', 'AMD', 'NVDA', 'GME', 'MU', 'TSLA', 'NFLX', 'ZG',\n",
    "    'AVGO', 'SMCI', 'GLW', 'HAL', 'LMT', 'AMZN', 'CRM', 'NOW', 'CHTR', 'TDS', 'META', 'RGTI','QUBT',\n",
    "    'LX', 'OKLO', 'PSIX', 'QFIN', 'RTX', 'TWLO'\n",
    "]\n",
    "\n",
    "def extract_stock_close(request):\n",
    "    \"\"\"Cloud Function to fetch current day stock data and save to BigQuery.\"\"\"\n",
    "    try:\n",
    "        # Define today's date and previous business day\n",
    "        today = datetime.today()\n",
    "        \n",
    "        # Adjust for weekends and market holidays\n",
    "        start_date = today - timedelta(days=3)\n",
    "        end_date = today\n",
    "        \n",
    "        logger.info(f\"Fetching stock data from {start_date} to {end_date}\")\n",
    "        \n",
    "        # Fetch stock data using a date range to ensure data availability\n",
    "        try:\n",
    "            stock_data = yf.download(TICKERS, start=start_date, end=end_date, group_by='ticker', threads=True)\n",
    "        except Exception as download_error:\n",
    "            logger.error(f\"Failed to download stock data: {download_error}\")\n",
    "            return f\"Failed to download stock data: {download_error}\"\n",
    "\n",
    "        # Check if data was returned\n",
    "        if stock_data.empty:\n",
    "            logger.warning(f\"No data available for date range {start_date} to {end_date}\")\n",
    "            return f\"No data available for date range {start_date} to {end_date}\"\n",
    "\n",
    "        # Create an empty list to store reformatted data\n",
    "        formatted_data = []\n",
    "\n",
    "        # Process each ticker to extract relevant information\n",
    "        for ticker in TICKERS:\n",
    "            try:\n",
    "                if ticker in stock_data.columns.get_level_values(0):  # Ensure ticker exists in data\n",
    "                    # Select the most recent day's data\n",
    "                    ticker_data = stock_data[ticker].iloc[-1]\n",
    "                    \n",
    "                    # Ensure we have valid data for the current day\n",
    "                    if pd.notna(ticker_data['Close']):\n",
    "                        # Calculate percent difference from the previous close\n",
    "                        try:\n",
    "                            previous_close = stock_data[ticker].iloc[-2]['Close']\n",
    "                            current_close = ticker_data['Close']\n",
    "                            percent_difference = ((current_close - previous_close) / previous_close)\n",
    "                        except (IndexError, TypeError):\n",
    "                            previous_close = None\n",
    "                            percent_difference = None\n",
    "\n",
    "                        # Append today's data\n",
    "                        formatted_data.append({\n",
    "                            \"Date\": today.strftime('%Y-%m-%d'),\n",
    "                            \"Ticker\": ticker,\n",
    "                            \"Close\": ticker_data['Close'],\n",
    "                            \"Volume\": ticker_data['Volume'],\n",
    "                            \"High\": ticker_data['High'],\n",
    "                            \"Low\": ticker_data['Low'],\n",
    "                            \"Open\": ticker_data['Open'],\n",
    "                            \"Percent_Difference\": percent_difference\n",
    "                        })\n",
    "            except Exception as ticker_error:\n",
    "                logger.error(f\"Error processing {ticker}: {ticker_error}\")\n",
    "                continue\n",
    "\n",
    "        # Convert the list of dictionaries to a DataFrame\n",
    "        reformatted_data = pd.DataFrame(formatted_data)\n",
    "\n",
    "        # Check if reformatted data is empty\n",
    "        if reformatted_data.empty:\n",
    "            logger.warning(f\"No valid stock data available for {today}\")\n",
    "            return f\"No valid stock data available for {today}\"\n",
    "\n",
    "        # Save to BigQuery\n",
    "        try:\n",
    "            client = bigquery.Client(project=PROJECT_ID)\n",
    "            table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
    "            \n",
    "            # Define job configuration\n",
    "            job_config = bigquery.LoadJobConfig(\n",
    "                write_disposition=bigquery.WriteDisposition.WRITE_APPEND,  # Append data if table exists\n",
    "                autodetect=True  # Automatically detect schema\n",
    "            )\n",
    "\n",
    "            # Load data to BigQuery\n",
    "            job = client.load_table_from_dataframe(\n",
    "                reformatted_data,\n",
    "                table_ref,\n",
    "                job_config=job_config\n",
    "            )\n",
    "            \n",
    "            # Wait for job to complete and log any errors\n",
    "            job.result()\n",
    "            \n",
    "            logger.info(f\"Stock data for {today} successfully saved to {table_ref}\")\n",
    "            return f\"Stock data for {today} successfully saved to {table_ref}\"\n",
    "\n",
    "        except Exception as bigquery_error:\n",
    "            logger.error(f\"BigQuery upload failed: {bigquery_error}\")\n",
    "            return f\"BigQuery upload failed: {bigquery_error}\"\n",
    "\n",
    "    except Exception as general_error:\n",
    "        logger.error(f\"Unexpected error in extract_stock_close: {general_error}\")\n",
    "        return f\"Unexpected error: {general_error}\"\n",
    "\n",
    "# Note: If this is a Google Cloud Function, you might need to add a trigger\n",
    "# such as a HTTP trigger or a scheduled cloud function trigger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yahooquery\n",
      "  Downloading yahooquery-2.3.7-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yahooquery) (4.12.3)\n",
      "Collecting lxml<5.0.0,>=4.9.3 (from yahooquery)\n",
      "  Downloading lxml-4.9.4-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.0.3 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yahooquery) (2.2.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yahooquery) (2.32.3)\n",
      "Collecting requests-futures<2.0.0,>=1.0.1 (from yahooquery)\n",
      "  Downloading requests_futures-1.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yahooquery) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.2->yahooquery) (2.6)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.0.3->yahooquery) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bryce\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0.0,>=2.0.3->yahooquery) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.0.3->yahooquery) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.0.3->yahooquery) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.31.0->yahooquery) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.31.0->yahooquery) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.31.0->yahooquery) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.31.0->yahooquery) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\bryce\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.65.0->yahooquery) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bryce\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.0.3->yahooquery) (1.16.0)\n",
      "Downloading yahooquery-2.3.7-py3-none-any.whl (52 kB)\n",
      "Downloading lxml-4.9.4-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 1.8/3.8 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading requests_futures-1.0.2-py2.py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: lxml, requests-futures, yahooquery\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 5.3.0\n",
      "    Uninstalling lxml-5.3.0:\n",
      "      Successfully uninstalled lxml-5.3.0\n",
      "Successfully installed lxml-4.9.4 requests-futures-1.0.2 yahooquery-2.3.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install yahooquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetching stock data from 2025-01-31 17:02:50.095980 to 2025-02-03 17:02:50.095980\n",
      "INFO:__main__:Fetching NASDAQ (^IXIC) data from 2024-12-01 00:00:00 to 2025-02-03 17:02:50.095980\n",
      "[************          24%                       ]  9 of 37 completedWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "[*************         27%                       ]  10 of 37 completedWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "[***************       32%                       ]  12 of 37 completedWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "[******************    38%                       ]  14 of 37 completedWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "[********************  41%                       ]  15 of 37 completedWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "[*********************100%***********************]  37 of 37 completed\n",
      "INFO:__main__:Stock data downloaded: 2 rows\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "INFO:__main__:NASDAQ data downloaded: (41, 6) rows and columns\n",
      "INFO:__main__:Saved output.csv for verification.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NASDAQ Column Names BEFORE FIX: MultiIndex([('Adj Close', '^IXIC'),\n",
      "            (    'Close', '^IXIC'),\n",
      "            (     'High', '^IXIC'),\n",
      "            (      'Low', '^IXIC'),\n",
      "            (     'Open', '^IXIC'),\n",
      "            (   'Volume', '^IXIC')],\n",
      "           names=['Price', 'Ticker'])\n",
      "\n",
      "NASDAQ Column Names FINAL: Index(['Date', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume'], dtype='object')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define stock tickers\n",
    "TICKERS = [\n",
    "    'AAPL', 'GOOGL', 'MSFT', 'ASTS', 'PTON', 'GSAT', 'PLTR', 'SMR', 'ACHR',\n",
    "    'BWXT', 'ARBK', 'AMD', 'NVDA', 'GME', 'MU', 'TSLA', 'NFLX', 'ZG',\n",
    "    'AVGO', 'SMCI', 'GLW', 'HAL', 'LMT', 'AMZN', 'CRM', 'NOW', 'CHTR', 'TDS', 'META', 'RGTI', 'QUBT',\n",
    "    'LX', 'OKLO', 'PSIX', 'QFIN', 'RTX', 'TWLO'\n",
    "]\n",
    "\n",
    "# NASDAQ Composite Index Ticker\n",
    "NASDAQ_TICKER = \"^IXIC\"\n",
    "\n",
    "def extract_stock_close():\n",
    "    \"\"\"Fetch stock data for normal tickers (past 3 days) and NASDAQ (^IXIC) (since Dec 1, 2024).\"\"\"\n",
    "    try:\n",
    "        today = datetime.today()\n",
    "        start_date = today - timedelta(days=3)  # Normal tickers (last 3 days)\n",
    "        nasdaq_start_date = datetime(2024, 12, 1)  # Fixed year for NASDAQ\n",
    "\n",
    "        logger.info(f\"Fetching stock data from {start_date} to {today}\")\n",
    "        logger.info(f\"Fetching NASDAQ (^IXIC) data from {nasdaq_start_date} to {today}\")\n",
    "\n",
    "        # Fetch stock data for normal tickers\n",
    "        try:\n",
    "            stock_data = yf.download(TICKERS, start=start_date, end=today, group_by='ticker', threads=5)\n",
    "            logger.info(f\"Stock data downloaded: {len(stock_data)} rows\")\n",
    "        except Exception as download_error:\n",
    "            logger.error(f\"Failed to download stock data: {download_error}\")\n",
    "            return\n",
    "        \n",
    "        # Fetch NASDAQ Composite Index (^IXIC) data\n",
    "        try:\n",
    "            nasdaq_data = yf.download(NASDAQ_TICKER, start=nasdaq_start_date, end=today)\n",
    "            logger.info(f\"NASDAQ data downloaded: {nasdaq_data.shape} rows and columns\")\n",
    "        except Exception as nasdaq_error:\n",
    "            logger.error(f\"Failed to download NASDAQ data: {nasdaq_error}\")\n",
    "            return\n",
    "\n",
    "        # Debug: Print column names before fixing\n",
    "        print(\"\\nNASDAQ Column Names BEFORE FIX:\", nasdaq_data.columns)\n",
    "\n",
    "        # ðŸ›  FIX: Flatten NASDAQ MultiIndex Columns\n",
    "        if isinstance(nasdaq_data.columns, pd.MultiIndex):\n",
    "            nasdaq_data.columns = [col[0] for col in nasdaq_data.columns]\n",
    "        nasdaq_data = nasdaq_data.reset_index()  # Convert Date index into a column\n",
    "\n",
    "        # Detect correct column names dynamically\n",
    "        column_map = {\n",
    "            \"Close\": None,\n",
    "            \"Open\": None,\n",
    "            \"High\": None,\n",
    "            \"Low\": None,\n",
    "            \"Volume\": None\n",
    "        }\n",
    "\n",
    "        for col in nasdaq_data.columns:\n",
    "            for key in column_map.keys():\n",
    "                if key in col:\n",
    "                    column_map[key] = col\n",
    "\n",
    "        # Rename columns using detected names\n",
    "        nasdaq_data = nasdaq_data.rename(columns=column_map)\n",
    "\n",
    "        # Debug: Print final column names after renaming\n",
    "        print(\"\\nNASDAQ Column Names FINAL:\", nasdaq_data.columns)\n",
    "\n",
    "        formatted_data = []\n",
    "\n",
    "        # Process normal tickers\n",
    "        for ticker in TICKERS:\n",
    "            try:\n",
    "                if ticker in stock_data.columns.get_level_values(0):\n",
    "                    ticker_data = stock_data[ticker].iloc[-1]  # Get latest data\n",
    "                    \n",
    "                    if pd.notna(ticker_data['Close']):\n",
    "                        # Find previous close safely\n",
    "                        previous_close = stock_data[ticker]['Close'].shift(1).iloc[-1]\n",
    "                        percent_difference = None\n",
    "                        \n",
    "                        if pd.notna(previous_close):\n",
    "                            percent_difference = ((ticker_data['Close'] - previous_close) / previous_close)\n",
    "\n",
    "                        formatted_data.append({\n",
    "                            \"Date\": today.strftime('%Y-%m-%d'),\n",
    "                            \"Ticker\": ticker,\n",
    "                            \"Close\": ticker_data['Close'],\n",
    "                            \"Volume\": ticker_data['Volume'],\n",
    "                            \"High\": ticker_data['High'],\n",
    "                            \"Low\": ticker_data['Low'],\n",
    "                            \"Open\": ticker_data['Open'],\n",
    "                            \"Percent_Difference\": percent_difference\n",
    "                        })\n",
    "            except Exception as ticker_error:\n",
    "                logger.error(f\"Error processing {ticker}: {ticker_error}\")\n",
    "                continue\n",
    "\n",
    "        # Process NASDAQ Data\n",
    "        for _, row in nasdaq_data.iterrows():\n",
    "            try:\n",
    "                # Compute percent difference safely\n",
    "                previous_close = nasdaq_data[\"Close\"].shift(1).iloc[-1] if len(nasdaq_data) > 1 else None\n",
    "                percent_difference = None\n",
    "\n",
    "                if pd.notna(previous_close):\n",
    "                    percent_difference = ((row[\"Close\"] - previous_close) / previous_close)\n",
    "\n",
    "                formatted_data.append({\n",
    "                    \"Date\": row[\"Date\"].strftime('%Y-%m-%d'),\n",
    "                    \"Ticker\": NASDAQ_TICKER,\n",
    "                    \"Close\": row[\"Close\"],\n",
    "                    \"Volume\": row[\"Volume\"] if \"Volume\" in nasdaq_data.columns else None,\n",
    "                    \"High\": row[\"High\"] if \"High\" in nasdaq_data.columns else None,\n",
    "                    \"Low\": row[\"Low\"] if \"Low\" in nasdaq_data.columns else None,\n",
    "                    \"Open\": row[\"Open\"] if \"Open\" in nasdaq_data.columns else None,\n",
    "                    \"Percent_Difference\": percent_difference\n",
    "                })\n",
    "            except Exception as nasdaq_error:\n",
    "                logger.error(f\"Error processing NASDAQ (^IXIC): {nasdaq_error}\")\n",
    "                continue\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        reformatted_data = pd.DataFrame(formatted_data)\n",
    "\n",
    "        # Save to CSV for debugging\n",
    "        reformatted_data.to_csv(\"output.csv\", index=False)\n",
    "        logger.info(\"Saved output.csv for verification.\")\n",
    "\n",
    "    except Exception as general_error:\n",
    "        logger.error(f\"Unexpected error: {general_error}\")\n",
    "\n",
    "# Run the function locally\n",
    "extract_stock_close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\BryceDaniel\\OneDrive\n",
      "[nltk_data]     - Lincoln Telephone\n",
      "[nltk_data]     Company\\MSBA\\GitHub\\TrendSense\\Market\n",
      "[nltk_data]     News\\Market_News_Yahoo_Extract_Function\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data successfully saved to market_news.csv\n"
     ]
    }
   ],
   "source": [
    "# Yahoo Extract with date restriction \n",
    "\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "# Explicitly set the nltk_data path\n",
    "nltk_data_path = r\"C:\\Users\\BryceDaniel\\OneDrive - Lincoln Telephone Company\\MSBA\\GitHub\\TrendSense\\Market News\\Market_News_Yahoo_Extract_Function\\nltk_data\"\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "# Ensure 'punkt' is downloaded into the correct folder\n",
    "nltk.download('punkt', download_dir=nltk_data_path)\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def calculate_sentiment(text):\n",
    "    try:\n",
    "        analysis = TextBlob(text)\n",
    "        return analysis.sentiment.polarity\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Sentiment analysis failed: {e}\")\n",
    "        return 0\n",
    "\n",
    "def label_sentiment(score):\n",
    "    if score > 0.35:\n",
    "        return \"Bullish\"\n",
    "    elif 0.15 < score <= 0.35:\n",
    "        return \"Somewhat-Bullish\"\n",
    "    elif -0.15 <= score <= 0.15:\n",
    "        return \"Neutral\"\n",
    "    elif -0.35 <= score < -0.15:\n",
    "        return \"Somewhat-Bearish\"\n",
    "    else:\n",
    "        return \"Bearish\"\n",
    "\n",
    "def get_market_news(tickers, days_back=2):\n",
    "    all_news = []\n",
    "    today = datetime.now().date()\n",
    "    cutoff_date = today - timedelta(days=days_back)\n",
    "\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        try:\n",
    "            news = stock.news\n",
    "            for item in news:\n",
    "                try:\n",
    "                    # Extract publish timestamp and date\n",
    "                    publish_timestamp = item.get('providerPublishTime', 0)\n",
    "                    publish_date = datetime.fromtimestamp(publish_timestamp).date()\n",
    "\n",
    "                    # Only process news within the desired date range\n",
    "                    if publish_date >= cutoff_date:\n",
    "                        title = item.get('title', '')\n",
    "                        sentiment_score = calculate_sentiment(title)\n",
    "                        sentiment_label = label_sentiment(sentiment_score)\n",
    "\n",
    "                        news_item = {\n",
    "                            'ticker': ticker,\n",
    "                            'title': title,\n",
    "                            'summary': title,  # Replicate title in the summary column\n",
    "                            'publisher': item.get('publisher', ''),\n",
    "                            'link': item.get('link', ''),\n",
    "                            'publish_date': datetime.fromtimestamp(publish_timestamp),\n",
    "                            'type': item.get('type', ''),\n",
    "                            'related_tickers': ', '.join(item.get('relatedTickers', [])),\n",
    "                            'source': 'yahoo',\n",
    "                            'overall_sentiment_score': sentiment_score,\n",
    "                            'overall_sentiment_label': sentiment_label,\n",
    "                        }\n",
    "                        all_news.append(news_item)\n",
    "                except Exception as news_item_error:\n",
    "                    print(f\"[ERROR] Error processing news item: {news_item_error}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Error retrieving news for {ticker}: {str(e)}\")\n",
    "    return pd.DataFrame(all_news)\n",
    "\n",
    "def save_to_csv(df, filename):\n",
    "    try:\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"[INFO] Data successfully saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to save data to CSV: {e}\")\n",
    "\n",
    "def fetch_and_save_market_news():\n",
    "    indices = ['^IXIC', '^DJI', '^RUT', '^GSPC']\n",
    "    market_news = get_market_news(tickers=indices)\n",
    "    if not market_news.empty:\n",
    "        market_news['category'] = 'General'\n",
    "\n",
    "    tech_stocks = [\n",
    "        'AAPL', 'GOOGL', 'MSFT', 'ASTS', 'PTON', 'GSAT', 'PLTR', 'SMR', 'ACHR',\n",
    "        'BWXT', 'ARBK', 'AMD', 'NVDA', 'BTC', 'GME', 'MU', 'TSLA', 'NFLX', 'ZG',\n",
    "        'AVGO', 'SMCI', 'GLW', 'HAL', 'LMT', 'AMZN', 'CRM', 'NOW', 'CHTR', 'TDS', 'META','RGTI','QUBT',\n",
    "        'LX', 'OKLO', 'PSIX', 'QFIN', 'RTX', 'TWLO'\n",
    "    ]\n",
    "    tech_news = get_market_news(tickers=tech_stocks)\n",
    "    if not tech_news.empty:\n",
    "        tech_news['category'] = 'Tech'\n",
    "\n",
    "    combined_news = pd.concat([market_news, tech_news], ignore_index=True)\n",
    "\n",
    "    if not combined_news.empty:\n",
    "        save_to_csv(combined_news, \"market_news.csv\")\n",
    "    else:\n",
    "        print(\"[INFO] No news data to save.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_and_save_market_news()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.50)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.54-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\bryce\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2024.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (3.17.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bryce\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bryce\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bryce\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Downloading yfinance-0.2.54-py2.py3-none-any.whl (108 kB)\n",
      "Installing collected packages: yfinance\n",
      "  Attempting uninstall: yfinance\n",
      "    Found existing installation: yfinance 0.2.50\n",
      "    Uninstalling yfinance-0.2.50:\n",
      "      Successfully uninstalled yfinance-0.2.50\n",
      "Successfully installed yfinance-0.2.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade yfinance\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yahoo Finance Targets:\n",
      "Recommendations:\n",
      "  period  strongBuy  buy  hold  sell  strongSell\n",
      "0     0m          2    3     0     0           0\n",
      "1    -1m          2    3     0     0           0\n",
      "2    -2m          2    3     0     0           0\n",
      "3    -3m          2    3     0     0           0\n",
      "\n",
      "Price Targets:\n",
      "Current Price: 25.645\n",
      "Target High Price: 53.0\n",
      "Target Low Price: 15.0\n",
      "Target Mean Price: 35.94\n",
      "Target Median Price: 36.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import yfinance as yf\n",
    "\n",
    "class StockPriceTargetRetriever:\n",
    "    def __init__(self, api_key=None):\n",
    "        \"\"\"\n",
    "        Initialize the Stock Price Target Retriever\n",
    "        \n",
    "        :param api_key: API key for paid services (optional)\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "    \n",
    "    def get_yahoo_finance_target(self, symbol):\n",
    "        \"\"\"\n",
    "        Retrieve price targets and recommendations from Yahoo Finance\n",
    "        \n",
    "        :param symbol: Stock ticker symbol\n",
    "        :return: Dictionary with recommendations and price targets\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Fetch the stock information\n",
    "            stock = yf.Ticker(symbol)\n",
    "            \n",
    "            # Fetch analyst recommendations\n",
    "            recommendations = stock.recommendations\n",
    "            \n",
    "            # Fetch analyst price targets\n",
    "            info = stock.info\n",
    "            \n",
    "            # Extract price target information from stock info\n",
    "            price_targets = {\n",
    "                'current_price': info.get('currentPrice'),\n",
    "                'target_high_price': info.get('targetHighPrice'),\n",
    "                'target_low_price': info.get('targetLowPrice'),\n",
    "                'target_mean_price': info.get('targetMeanPrice'),\n",
    "                'target_median_price': info.get('targetMedianPrice')\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                'recommendations': recommendations,\n",
    "                'price_targets': price_targets\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching Yahoo Finance data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_alpha_vantage_overview(self, symbol):\n",
    "        \"\"\"\n",
    "        Retrieve stock overview from Alpha Vantage\n",
    "        \n",
    "        :param symbol: Stock ticker symbol\n",
    "        :return: Dictionary of stock overview data\n",
    "        \"\"\"\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"Alpha Vantage requires an API key\")\n",
    "        \n",
    "        url = f'https://www.alphavantage.co/query?function=OVERVIEW&symbol={symbol}&apikey={self.api_key}'\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching data from Alpha Vantage: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_financial_modeling_prep_target(self, symbol):\n",
    "        \"\"\"\n",
    "        Retrieve price targets from Financial Modeling Prep\n",
    "        \n",
    "        :param symbol: Stock ticker symbol\n",
    "        :return: List of price target data\n",
    "        \"\"\"\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"Financial Modeling Prep requires an API key\")\n",
    "        \n",
    "        url = f'https://financialmodelingprep.com/api/v3/price-target?symbol={symbol}&apikey={self.api_key}'\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching data from Financial Modeling Prep: {e}\")\n",
    "            return None\n",
    "\n",
    "def main():\n",
    "    # Initialize the retriever\n",
    "    retriever = StockPriceTargetRetriever()\n",
    "    \n",
    "    # Retrieve price targets for Apple (AAPL)\n",
    "    symbol = 'ASTS'\n",
    "    \n",
    "    # Yahoo Finance (completely free)\n",
    "    yahoo_targets = retriever.get_yahoo_finance_target(symbol)\n",
    "    \n",
    "    # Print results with error handling\n",
    "    if yahoo_targets:\n",
    "        print(\"Yahoo Finance Targets:\")\n",
    "        print(\"Recommendations:\")\n",
    "        print(yahoo_targets.get('recommendations', 'No recommendations available'))\n",
    "        print(\"\\nPrice Targets:\")\n",
    "        price_targets = yahoo_targets.get('price_targets', {})\n",
    "        for key, value in price_targets.items():\n",
    "            print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve stock information.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# Important Notes:\n",
    "# 1. This script requires yfinance library\n",
    "# 2. Install dependencies: pip install yfinance requests\n",
    "# 3. Be aware of potential rate limits or changes in Yahoo Finance's structure\n",
    "\n",
    "# Troubleshooting:\n",
    "# - Ensure you have the latest version of yfinance\n",
    "# - Some stock symbols might not have complete information\n",
    "# - Network connectivity can affect data retrieval\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent successfully.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BryceDaniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Skipping non-story type: VIDEO\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/p-500-closes-record-high-213627406.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/p-500-closes-record-high-213627406.html: name 'requests' is not defined\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/live/stock-market-today-sp-500-clinches-first-record-close-of-2025-dow-pops-after-trump-takes-spotlight-at-davos-210311077.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/live/stock-market-today-sp-500-clinches-first-record-close-of-2025-dow-pops-after-trump-takes-spotlight-at-davos-210311077.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-comments-leave-equity-markets-205020322.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-comments-leave-equity-markets-205020322.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-comments-leave-equities-mixed-185441569.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-comments-leave-equities-mixed-185441569.html: name 'requests' is not defined\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/live/stock-market-today-sp-500-clinches-first-record-close-of-2025-dow-pops-after-trump-takes-spotlight-at-davos-210311077.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/live/stock-market-today-sp-500-clinches-first-record-close-of-2025-dow-pops-after-trump-takes-spotlight-at-davos-210311077.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/top-cryptocurrencies-fall-bitcoin-drops-210004065.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/top-cryptocurrencies-fall-bitcoin-drops-210004065.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-comments-leave-equity-markets-205020322.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-comments-leave-equity-markets-205020322.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/us-equity-indexes-mixed-technology-182320372.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/us-equity-indexes-mixed-technology-182320372.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/initial-claims-higher-estimates-155300236.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/initial-claims-higher-estimates-155300236.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/pre-markets-seek-direction-warmer-153200988.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/pre-markets-seek-direction-warmer-153200988.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/vanguard-russell-2000-value-etf-112008096.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/vanguard-russell-2000-value-etf-112008096.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/asian-shares-ride-wall-street-224004019.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/asian-shares-ride-wall-street-224004019.html: name 'requests' is not defined\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/3eaea4ff-1238-3bd0-84c5-ef7aedf91b70/why-prologis-stock-was-a.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/3eaea4ff-1238-3bd0-84c5-ef7aedf91b70/why-prologis-stock-was-a.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/brf-brfs-stock-falls-amid-230024316.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/brf-brfs-stock-falls-amid-230024316.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/cloudflare-net-rises-higher-market-230024297.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/cloudflare-net-rises-higher-market-230024297.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/monday-com-mndy-stock-drops-230023207.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/monday-com-mndy-stock-drops-230023207.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/cadence-design-systems-cdns-outperforms-230022774.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/cadence-design-systems-cdns-outperforms-230022774.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/gold-fields-gfi-gains-lags-230021576.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/gold-fields-gfi-gains-lags-230021576.html: name 'requests' is not defined\n",
      "[INFO] Fetched 21 news articles.\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-224128923.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-224128923.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/d6ad7585-fc9b-3f5f-9207-11c2c3f75d3c/former-apple-executive-asks.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/d6ad7585-fc9b-3f5f-9207-11c2c3f75d3c/former-apple-executive-asks.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/apple-poised-largely-line-first-204840044.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/apple-poised-largely-line-first-204840044.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/6ec2f756-d24d-3154-a494-c4f23da4bd4f/as-apple-earnings-near%2C-more.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/6ec2f756-d24d-3154-a494-c4f23da4bd4f/as-apple-earnings-near%2C-more.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/apple-inc-aapl-among-billionaire-195410392.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/apple-inc-aapl-among-billionaire-195410392.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-194817735.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-194817735.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/india-urges-apple-google-host-185435371.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/india-urges-apple-google-host-185435371.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-224128923.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-224128923.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/aed87e43-725f-39b2-8531-1c08e0b941e7/ibd-50-stock-in-huge-demand-%E2%80%94.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/aed87e43-725f-39b2-8531-1c08e0b941e7/ibd-50-stock-in-huge-demand-%E2%80%94.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/alphabet-inc-googl-best-socially-202310113.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/alphabet-inc-googl-best-socially-202310113.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-194817735.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-194817735.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/india-urges-apple-google-host-185435371.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/india-urges-apple-google-host-185435371.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/0df94b1f-418c-3bdb-9d48-4ec50838622f/apple-2025-outlook%3A-ai-gets.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/0df94b1f-418c-3bdb-9d48-4ec50838622f/apple-2025-outlook%3A-ai-gets.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/d30567e5-9a57-37bc-a44c-fc2bda988228/researchers-just-stumped-ai.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/d30567e5-9a57-37bc-a44c-fc2bda988228/researchers-just-stumped-ai.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/tevogen-bio-highlights-future-ai-005300691.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/tevogen-bio-highlights-future-ai-005300691.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/sector-tech-stocks-edge-lower-205709720.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/sector-tech-stocks-edge-lower-205709720.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/sector-tech-204124549.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/sector-tech-204124549.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/hp-stockpiling-computers-ahead-of-potential-trump-tariffs-ceo-203002131.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/hp-stockpiling-computers-ahead-of-potential-trump-tariffs-ceo-203002131.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/microsoft-corporation-msft-among-billionaire-195046386.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/microsoft-corporation-msft-among-billionaire-195046386.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/5dd00a9b-8305-3862-b01d-ed9edac80eb4/microsoft-stock-approaches.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/5dd00a9b-8305-3862-b01d-ed9edac80eb4/microsoft-stock-approaches.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/market-chatter-microsoft-train-1-193338908.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/market-chatter-microsoft-train-1-193338908.html: name 'requests' is not defined\n",
      "[INFO] Fetched 24 news articles.\n",
      "[INFO] News data saved locally at: market_news\\market_news_20250124_100549.csv\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "\n",
    "# Ensure the required NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "def fetch_article_summary(link):\n",
    "    \"\"\"\n",
    "    Fetch and summarize the article content from a URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use Newspaper3k with headers\n",
    "        article = Article(link)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        return article.summary\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Newspaper3k failed for {link}: {str(e)}. Falling back to BeautifulSoup.\")\n",
    "\n",
    "        # Fallback to BeautifulSoup\n",
    "        try:\n",
    "            response = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            paragraphs = soup.find_all(\"p\")\n",
    "            content = \" \".join([p.get_text() for p in paragraphs])\n",
    "            return content[:500] + \"...\" if len(content) > 500 else content\n",
    "        except Exception as bs_error:\n",
    "            print(f\"[ERROR] BeautifulSoup also failed for {link}: {str(bs_error)}\")\n",
    "            return \"No summary available.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_market_news(tickers):\n",
    "    \"\"\"\n",
    "    Fetch market news for the current day, capturing all available fields and generating summaries.\n",
    "    Only processes news items with 'type' set to 'story'.\n",
    "    \"\"\"\n",
    "    all_news = []\n",
    "    today = datetime.now().date()\n",
    "    one_day_ago = today - timedelta(days=1)\n",
    "\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "\n",
    "        try:\n",
    "            news = stock.news\n",
    "            for item in news:\n",
    "                try:\n",
    "                    publish_timestamp = item.get('providerPublishTime', 0)\n",
    "                    publish_date = datetime.fromtimestamp(publish_timestamp).date()\n",
    "\n",
    "                    # Filter news to include only today's and yesterday's articles\n",
    "                    if publish_date >= one_day_ago:\n",
    "                        # Only summarize articles with type 'story'\n",
    "                        if item.get('type', '').lower() == 'story':\n",
    "                            link = item.get('link', '')\n",
    "                            summary = fetch_article_summary(link) if link else \"No summary available.\"\n",
    "\n",
    "                            news_item = {\n",
    "                                'ticker': ticker,\n",
    "                                'title': item.get('title', ''),\n",
    "                                'publisher': item.get('publisher', ''),\n",
    "                                'link': link,\n",
    "                                'publish_date': datetime.fromtimestamp(publish_timestamp),\n",
    "                                'summary': summary,  # Include the generated summary\n",
    "                                'type': item.get('type', ''),  # Original type from Yahoo API\n",
    "                                'related_tickers': ', '.join(item.get('relatedTickers', [])),  # Comma-separated related tickers\n",
    "                            }\n",
    "                            all_news.append(news_item)\n",
    "                        else:\n",
    "                            print(f\"[INFO] Skipping non-story type: {item.get('type', '')}\")\n",
    "                except Exception as news_item_error:\n",
    "                    print(f\"[ERROR] Error processing news item: {news_item_error}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Error retrieving news for {ticker}: {str(e)}\")\n",
    "\n",
    "    print(f\"[INFO] Fetched {len(all_news)} news articles.\")\n",
    "    return pd.DataFrame(all_news)\n",
    "\n",
    "\n",
    "def save_to_csv(df, output_dir=\"market_news\"):\n",
    "    \"\"\"\n",
    "    Save processed news data to a CSV file locally.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if df.empty:\n",
    "            print(\"[INFO] No news data to save.\")\n",
    "            return None\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filename = f\"market_news_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        df.to_csv(filepath, index=False, encoding=\"utf-8\")\n",
    "        print(f\"[INFO] News data saved locally at: {filepath}\")\n",
    "        return filepath\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to save CSV: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function for fetching and saving market news locally.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch general market news\n",
    "        indices = ['^IXIC', '^DJI', '^RUT', '^GSPC']\n",
    "        market_news = get_market_news(tickers=indices)\n",
    "        if not market_news.empty:\n",
    "            market_news['category'] = 'General'  # Add category for general market\n",
    "\n",
    "        # Fetch tech stock news\n",
    "        tech_stocks = ['AAPL', 'GOOGL', 'MSFT']\n",
    "        tech_news = get_market_news(tickers=tech_stocks)\n",
    "        if not tech_news.empty:\n",
    "            tech_news['category'] = 'Tech'  # Add category for tech stocks\n",
    "\n",
    "        # Combine news\n",
    "        combined_news = pd.concat([market_news, tech_news], ignore_index=True)\n",
    "\n",
    "        # Save to CSV locally\n",
    "        if not combined_news.empty:\n",
    "            save_to_csv(combined_news)\n",
    "        else:\n",
    "            print(\"[INFO] No news data to save.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error in main function: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
