{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been exported to aggregated_data_with_top_10_analysis.csv\n",
      "\n",
      "Sample of top 10 performance:\n",
      "\n",
      "Date: 2024-12-17\n",
      "  ticker  Composite_Rank  Avg_Next_Daily_Percent_Difference  \\\n",
      "0   AAPL             NaN                          -2.142178   \n",
      "1     MU             NaN                          -4.327806   \n",
      "2     ZG             NaN                           1.878184   \n",
      "3    TDS             NaN                          -2.015413   \n",
      "4   PLTR             NaN                          -3.871484   \n",
      "5    SMR             NaN                         -11.976041   \n",
      "6    HAL             NaN                          -3.824939   \n",
      "7   META             NaN                          -3.591954   \n",
      "8   ACHR             NaN                          -1.540158   \n",
      "9   NVDA             NaN                          -1.135053   \n",
      "\n",
      "   Top_10_Next_Day_Avg  \n",
      "0             -4.29219  \n",
      "1             -4.29219  \n",
      "2             -4.29219  \n",
      "3             -4.29219  \n",
      "4             -4.29219  \n",
      "5             -4.29219  \n",
      "6             -4.29219  \n",
      "7             -4.29219  \n",
      "8             -4.29219  \n",
      "9             -4.29219  \n",
      "\n",
      "Date: 2024-12-18\n",
      "   ticker  Composite_Rank  Avg_Next_Daily_Percent_Difference  \\\n",
      "24   GSAT             3.0                           1.621620   \n",
      "36    CRM             5.0                          -0.296534   \n",
      "37   NVDA             5.0                           1.373042   \n",
      "27  GOOGL             7.0                           0.058387   \n",
      "30   MSFT             7.5                          -0.082310   \n",
      "31    AMD             7.5                          -2.083853   \n",
      "42   NFLX             9.0                           1.404080   \n",
      "35    HAL             9.5                          -1.453152   \n",
      "40    NOW            10.0                           1.308213   \n",
      "43   PLTR            10.5                           3.775691   \n",
      "\n",
      "    Top_10_Next_Day_Avg  \n",
      "24             0.562518  \n",
      "36             0.562518  \n",
      "37             0.562518  \n",
      "27             0.562518  \n",
      "30             0.562518  \n",
      "31             0.562518  \n",
      "42             0.562518  \n",
      "35             0.562518  \n",
      "40             0.562518  \n",
      "43             0.562518  \n",
      "\n",
      "Date: 2024-12-19\n",
      "   ticker  Composite_Rank  Avg_Next_Daily_Percent_Difference  \\\n",
      "55    HAL             7.5                           0.776092   \n",
      "58   GSAT             7.5                           3.723407   \n",
      "48   MSFT             8.0                          -0.098390   \n",
      "51   SMCI             8.0                           1.120360   \n",
      "59   NVDA             8.0                           3.076220   \n",
      "49    AMD             9.5                           0.277592   \n",
      "54    TDS             9.5                          -0.970297   \n",
      "62   AAPL             9.5                           1.881585   \n",
      "57    SMR            10.0                           3.997897   \n",
      "60   PLTR            10.0                           8.543328   \n",
      "\n",
      "    Top_10_Next_Day_Avg  \n",
      "55              2.23278  \n",
      "58              2.23278  \n",
      "48              2.23278  \n",
      "51              2.23278  \n",
      "59              2.23278  \n",
      "49              2.23278  \n",
      "54              2.23278  \n",
      "62              2.23278  \n",
      "57              2.23278  \n",
      "60              2.23278  \n",
      "\n",
      "Overall average next-day performance of top 10 strategy: 0.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryce\\AppData\\Local\\Temp\\ipykernel_30932\\3251110468.py:94: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.nsmallest(10, 'Composite_Rank')['Avg_Next_Daily_Percent_Difference'].mean())\n",
      "C:\\Users\\Bryce\\AppData\\Local\\Temp\\ipykernel_30932\\3251110468.py:101: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.nsmallest(10, 'Composite_Rank')['Avg_Daily_Percent_Difference'].mean())\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# SQL Query to clean and aggregate the data\n",
    "query = \"\"\"\n",
    "WITH cleaned_data AS (\n",
    "  SELECT\n",
    "    ticker,\n",
    "    DATE(date) AS date,\n",
    "    Stock_Category,\n",
    "    Aggregated_Score,\n",
    "    Daily_Percent_Difference,\n",
    "    Next_Daily_Percent_Difference,\n",
    "    AI_Score,\n",
    "    `Sentiment Score`,\n",
    "    Health_Score\n",
    "  FROM\n",
    "    `trendsense.combined_data.step_3_predictive_1`\n",
    "  WHERE\n",
    "    Aggregated_Score IS NOT NULL AND Aggregated_Score != 0\n",
    "    -- AND Daily_Percent_Difference IS NOT NULL AND Daily_Percent_Difference != 0\n",
    "    -- AND Next_Daily_Percent_Difference IS NOT NULL AND Next_Daily_Percent_Difference != 0\n",
    "    AND AI_Score IS NOT NULL AND AI_Score != 0\n",
    "    AND `Sentiment Score` IS NOT NULL AND `Sentiment Score` != 0\n",
    "    AND Health_Score IS NOT NULL AND Health_Score != 0\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  ticker,\n",
    "  date,\n",
    "  Stock_Category,\n",
    "  AVG(Aggregated_Score) AS Avg_Aggregated_Score,\n",
    "  AVG(Daily_Percent_Difference) AS Avg_Daily_Percent_Difference,\n",
    "  AVG(Next_Daily_Percent_Difference) AS Avg_Next_Daily_Percent_Difference,\n",
    "  AVG(AI_Score) AS Avg_AI_Score,\n",
    "  AVG(`Sentiment Score`) AS Avg_Sentiment_Score,\n",
    "  AVG(Health_Score) AS Avg_Health_Score\n",
    "FROM\n",
    "  cleaned_data\n",
    "GROUP BY\n",
    "  ticker,\n",
    "  date,\n",
    "  Stock_Category\n",
    "ORDER BY\n",
    "  ticker,\n",
    "  date;\n",
    "\"\"\"\n",
    "\n",
    "# Run the query and convert results to DataFrame\n",
    "query_job = client.query(query)\n",
    "df = query_job.to_dataframe()\n",
    "\n",
    "# Count number of rows per date\n",
    "df['date_count'] = df.groupby('date')['date'].transform('count')\n",
    "\n",
    "# Filter out rows where there are fewer than 5 rows for a given date\n",
    "df = df[df['date_count'] >= 5]\n",
    "\n",
    "# Drop the helper column\n",
    "df = df.drop(columns=['date_count'])\n",
    "\n",
    "# Sort the DataFrame by ticker and date to ensure correct calculations\n",
    "df = df.sort_values(['ticker', 'date'])\n",
    "\n",
    "# Calculate 7-day rolling average for each ticker separately\n",
    "df['Rolling_7day_Avg'] = df.groupby('ticker')['Avg_Aggregated_Score'].transform(\n",
    "    lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "# Add daily ranking based on Rolling_7day_Avg (1 is highest)\n",
    "df['Rolling_Avg_Rank'] = df.groupby('date')['Rolling_7day_Avg'].rank(\n",
    "    method='min',     # Use minimum rank for ties\n",
    "    ascending=False,  # Higher values get lower rank numbers\n",
    ")\n",
    "\n",
    "# Calculate percent difference from previous day for each ticker\n",
    "df['Pct_Change_From_Previous'] = df.groupby('ticker')['Avg_Aggregated_Score'].pct_change() * 100\n",
    "\n",
    "# Add daily ranking based on percent change (1 is highest percent increase)\n",
    "df['Pct_Change_Rank'] = df.groupby('date')['Pct_Change_From_Previous'].rank(\n",
    "    method='min',     # Use minimum rank for ties\n",
    "    ascending=False,  # Higher values get lower rank numbers\n",
    ")\n",
    "\n",
    "# Calculate the average of both rankings\n",
    "df['Composite_Rank'] = (df['Rolling_Avg_Rank'] + df['Pct_Change_Rank']) / 2\n",
    "\n",
    "# Create temporary dataframe with top 10 averages per day\n",
    "daily_top_10_avg_next = (\n",
    "    df.groupby('date')\n",
    "    .apply(lambda x: x.nsmallest(10, 'Composite_Rank')['Avg_Next_Daily_Percent_Difference'].mean())\n",
    "    .reset_index()\n",
    "    .rename(columns={0: 'Top_10_Next_Day_Avg'})\n",
    ")\n",
    "\n",
    "daily_top_10_avg_today = (\n",
    "    df.groupby('date')\n",
    "    .apply(lambda x: x.nsmallest(10, 'Composite_Rank')['Avg_Daily_Percent_Difference'].mean())\n",
    "    .reset_index()\n",
    "    .rename(columns={0: 'Top_10_Today_Day_Avg'})\n",
    ")\n",
    "\n",
    "# Merge the daily averages back to the main dataframe\n",
    "df = df.merge(daily_top_10_avg_next, on='date', how='left')\n",
    "df = df.merge(daily_top_10_avg_today, on='date', how='left')\n",
    "\n",
    "\n",
    "# Ensure data is sorted by date\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# Aggregate by date: take the average of Top_10_Next_Day_Avg per day\n",
    "daily_cumulative = (\n",
    "    df.groupby('date')['Top_10_Next_Day_Avg']\n",
    "    .mean()  # Take the average instead of sum\n",
    "    .cumsum()  # Compute cumulative sum of daily averages\n",
    "    .reset_index()\n",
    "    .rename(columns={'Top_10_Next_Day_Avg': 'Cumulative_Top_10_Score'})\n",
    ")\n",
    "\n",
    "# Merge back to main dataframe\n",
    "df = df.merge(daily_cumulative, on='date', how='left')\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file_path = 'aggregated_data_with_top_10_analysis.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been exported to {csv_file_path}\")\n",
    "\n",
    "# Display some summary statistics\n",
    "print(\"\\nSample of top 10 performance:\")\n",
    "sample_days = df['date'].unique()[:3]  # Get first 3 unique dates\n",
    "for day in sample_days:\n",
    "    print(f\"\\nDate: {day}\")\n",
    "    print(df[df['date'] == day].nsmallest(10, 'Composite_Rank')[\n",
    "        ['ticker', 'Composite_Rank', 'Avg_Next_Daily_Percent_Difference', 'Top_10_Next_Day_Avg']\n",
    "    ])\n",
    "\n",
    "# Calculate overall average performance of top 10 strategy\n",
    "overall_avg = df['Top_10_Next_Day_Avg'].mean()\n",
    "print(f\"\\nOverall average next-day performance of top 10 strategy: {overall_avg:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to financial_news_with_scores.csv\n"
     ]
    }
   ],
   "source": [
    "# Rev 2\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Initialize the OpenAI client (replace 'your_api_key' with your actual key)\n",
    "client = openai.OpenAI(api_key=\"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\")\n",
    "\n",
    "def extract_numeric_score(response):\n",
    "    \"\"\"Extracts the first valid float from the OpenAI response.\"\"\"\n",
    "    match = re.search(r\"-?\\d+(\\.\\d+)?\", response)\n",
    "    if match:\n",
    "        return float(match.group(0))\n",
    "    return None\n",
    "\n",
    "def get_financial_impact(title, ticker):\n",
    "    \"\"\"Analyzes financial market impact from the perspective of a specific ticker.\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert financial analyst specializing in stock market movements.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                Evaluate the financial market impact of this headline from the perspective of **{ticker}**. Assign a **precise** numerical score between -10 and 10.\n",
    "\n",
    "                **GUIDELINES:**\n",
    "                - **Perspective Matters**: The score should reflect how this affects **{ticker}**, not just the industry as a whole.\n",
    "                - **Competitive Awareness**: If the news benefits a competitor, it may negatively impact **{ticker}**.\n",
    "                - **Market Sentiment**: Weigh factors like stock movements, investor reactions, regulatory concerns, or sector trends.\n",
    "                - **STRICT FORMAT**: The response must contain only a **single** numerical value (e.g., -7.5, 3.2, 0). No explanations or extra text.\n",
    "\n",
    "                **News Headline:** \"{title}\"\n",
    "\n",
    "                **ONLY OUTPUT A SINGLE NUMBER:**\"\"\"}\n",
    "            ],\n",
    "            max_tokens=10,\n",
    "            temperature=0.5\n",
    "        )\n",
    "\n",
    "        raw_response = completion.choices[0].message.content.strip()\n",
    "        \n",
    "        score = extract_numeric_score(raw_response)\n",
    "        if score is not None and -10 <= score <= 10:\n",
    "            return score\n",
    "        else:\n",
    "            print(f\"Invalid numeric response for '{title}' (Ticker: {ticker}): {raw_response}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing title: {title} (Ticker: {ticker})\\nError: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"financial_news.csv\")\n",
    "\n",
    "# Ensure the dataset contains the required columns\n",
    "if \"title\" in df.columns and \"ticker\" in df.columns:\n",
    "    df[\"financial_impact_score\"] = df.apply(lambda row: get_financial_impact(row[\"title\"], row[\"ticker\"]), axis=1)\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(\"financial_news_with_scoresCL4.csv\", index=False)\n",
    "\n",
    "print(\"Data saved to financial_news_with_scores.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from google.cloud import bigquery\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define BigQuery dataset and table\n",
    "PROJECT_ID = \"trendsense\"\n",
    "DATASET_ID = \"stock_data\"\n",
    "TABLE_ID = \"stock_data_history\"\n",
    "\n",
    "# Define the list of stock tickers\n",
    "TICKERS = [\n",
    "    'AAPL', 'GOOGL', 'MSFT', 'ASTS', 'PTON', 'GSAT', 'PLTR', 'SMR', 'ACHR',\n",
    "    'BWXT', 'ARBK', 'AMD', 'NVDA', 'GME', 'MU', 'TSLA', 'NFLX', 'ZG',\n",
    "    'AVGO', 'SMCI', 'GLW', 'HAL', 'LMT', 'AMZN', 'CRM', 'NOW', 'CHTR', 'TDS', 'META', 'RGTI','QUBT',\n",
    "    'LX', 'OKLO', 'PSIX', 'QFIN', 'RTX', 'TWLO'\n",
    "]\n",
    "\n",
    "def extract_stock_close(request):\n",
    "    \"\"\"Cloud Function to fetch current day stock data and save to BigQuery.\"\"\"\n",
    "    try:\n",
    "        # Define today's date and previous business day\n",
    "        today = datetime.today()\n",
    "        \n",
    "        # Adjust for weekends and market holidays\n",
    "        start_date = today - timedelta(days=3)\n",
    "        end_date = today\n",
    "        \n",
    "        logger.info(f\"Fetching stock data from {start_date} to {end_date}\")\n",
    "        \n",
    "        # Fetch stock data using a date range to ensure data availability\n",
    "        try:\n",
    "            stock_data = yf.download(TICKERS, start=start_date, end=end_date, group_by='ticker', threads=True)\n",
    "        except Exception as download_error:\n",
    "            logger.error(f\"Failed to download stock data: {download_error}\")\n",
    "            return f\"Failed to download stock data: {download_error}\"\n",
    "\n",
    "        # Check if data was returned\n",
    "        if stock_data.empty:\n",
    "            logger.warning(f\"No data available for date range {start_date} to {end_date}\")\n",
    "            return f\"No data available for date range {start_date} to {end_date}\"\n",
    "\n",
    "        # Create an empty list to store reformatted data\n",
    "        formatted_data = []\n",
    "\n",
    "        # Process each ticker to extract relevant information\n",
    "        for ticker in TICKERS:\n",
    "            try:\n",
    "                if ticker in stock_data.columns.get_level_values(0):  # Ensure ticker exists in data\n",
    "                    # Select the most recent day's data\n",
    "                    ticker_data = stock_data[ticker].iloc[-1]\n",
    "                    \n",
    "                    # Ensure we have valid data for the current day\n",
    "                    if pd.notna(ticker_data['Close']):\n",
    "                        # Calculate percent difference from the previous close\n",
    "                        try:\n",
    "                            previous_close = stock_data[ticker].iloc[-2]['Close']\n",
    "                            current_close = ticker_data['Close']\n",
    "                            percent_difference = ((current_close - previous_close) / previous_close)\n",
    "                        except (IndexError, TypeError):\n",
    "                            previous_close = None\n",
    "                            percent_difference = None\n",
    "\n",
    "                        # Append today's data\n",
    "                        formatted_data.append({\n",
    "                            \"Date\": today.strftime('%Y-%m-%d'),\n",
    "                            \"Ticker\": ticker,\n",
    "                            \"Close\": ticker_data['Close'],\n",
    "                            \"Volume\": ticker_data['Volume'],\n",
    "                            \"High\": ticker_data['High'],\n",
    "                            \"Low\": ticker_data['Low'],\n",
    "                            \"Open\": ticker_data['Open'],\n",
    "                            \"Percent_Difference\": percent_difference\n",
    "                        })\n",
    "            except Exception as ticker_error:\n",
    "                logger.error(f\"Error processing {ticker}: {ticker_error}\")\n",
    "                continue\n",
    "\n",
    "        # Convert the list of dictionaries to a DataFrame\n",
    "        reformatted_data = pd.DataFrame(formatted_data)\n",
    "\n",
    "        # Check if reformatted data is empty\n",
    "        if reformatted_data.empty:\n",
    "            logger.warning(f\"No valid stock data available for {today}\")\n",
    "            return f\"No valid stock data available for {today}\"\n",
    "\n",
    "        # Save to BigQuery\n",
    "        try:\n",
    "            client = bigquery.Client(project=PROJECT_ID)\n",
    "            table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
    "            \n",
    "            # Define job configuration\n",
    "            job_config = bigquery.LoadJobConfig(\n",
    "                write_disposition=bigquery.WriteDisposition.WRITE_APPEND,  # Append data if table exists\n",
    "                autodetect=True  # Automatically detect schema\n",
    "            )\n",
    "\n",
    "            # Load data to BigQuery\n",
    "            job = client.load_table_from_dataframe(\n",
    "                reformatted_data,\n",
    "                table_ref,\n",
    "                job_config=job_config\n",
    "            )\n",
    "            \n",
    "            # Wait for job to complete and log any errors\n",
    "            job.result()\n",
    "            \n",
    "            logger.info(f\"Stock data for {today} successfully saved to {table_ref}\")\n",
    "            return f\"Stock data for {today} successfully saved to {table_ref}\"\n",
    "\n",
    "        except Exception as bigquery_error:\n",
    "            logger.error(f\"BigQuery upload failed: {bigquery_error}\")\n",
    "            return f\"BigQuery upload failed: {bigquery_error}\"\n",
    "\n",
    "    except Exception as general_error:\n",
    "        logger.error(f\"Unexpected error in extract_stock_close: {general_error}\")\n",
    "        return f\"Unexpected error: {general_error}\"\n",
    "\n",
    "# Note: If this is a Google Cloud Function, you might need to add a trigger\n",
    "# such as a HTTP trigger or a scheduled cloud function trigger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fetching stock data from 2025-01-31 17:02:50.095980 to 2025-02-03 17:02:50.095980\n",
      "INFO:__main__:Fetching NASDAQ (^IXIC) data from 2024-12-01 00:00:00 to 2025-02-03 17:02:50.095980\n",
      "[************          24%                       ]  9 of 37 completedWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "[*************         27%                       ]  10 of 37 completedWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "[***************       32%                       ]  12 of 37 completedWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "[******************    38%                       ]  14 of 37 completedWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "[********************  41%                       ]  15 of 37 completedWARNING:urllib3.connectionpool:Connection pool is full, discarding connection: query2.finance.yahoo.com. Connection pool size: 10\n",
      "[*********************100%***********************]  37 of 37 completed\n",
      "INFO:__main__:Stock data downloaded: 2 rows\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "INFO:__main__:NASDAQ data downloaded: (41, 6) rows and columns\n",
      "INFO:__main__:Saved output.csv for verification.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NASDAQ Column Names BEFORE FIX: MultiIndex([('Adj Close', '^IXIC'),\n",
      "            (    'Close', '^IXIC'),\n",
      "            (     'High', '^IXIC'),\n",
      "            (      'Low', '^IXIC'),\n",
      "            (     'Open', '^IXIC'),\n",
      "            (   'Volume', '^IXIC')],\n",
      "           names=['Price', 'Ticker'])\n",
      "\n",
      "NASDAQ Column Names FINAL: Index(['Date', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume'], dtype='object')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define stock tickers\n",
    "TICKERS = [\n",
    "    'AAPL', 'GOOGL', 'MSFT', 'ASTS', 'PTON', 'GSAT', 'PLTR', 'SMR', 'ACHR',\n",
    "    'BWXT', 'ARBK', 'AMD', 'NVDA', 'GME', 'MU', 'TSLA', 'NFLX', 'ZG',\n",
    "    'AVGO', 'SMCI', 'GLW', 'HAL', 'LMT', 'AMZN', 'CRM', 'NOW', 'CHTR', 'TDS', 'META', 'RGTI', 'QUBT',\n",
    "    'LX', 'OKLO', 'PSIX', 'QFIN', 'RTX', 'TWLO'\n",
    "]\n",
    "\n",
    "# NASDAQ Composite Index Ticker\n",
    "NASDAQ_TICKER = \"^IXIC\"\n",
    "\n",
    "def extract_stock_close():\n",
    "    \"\"\"Fetch stock data for normal tickers (past 3 days) and NASDAQ (^IXIC) (since Dec 1, 2024).\"\"\"\n",
    "    try:\n",
    "        today = datetime.today()\n",
    "        start_date = today - timedelta(days=3)  # Normal tickers (last 3 days)\n",
    "        nasdaq_start_date = datetime(2024, 12, 1)  # Fixed year for NASDAQ\n",
    "\n",
    "        logger.info(f\"Fetching stock data from {start_date} to {today}\")\n",
    "        logger.info(f\"Fetching NASDAQ (^IXIC) data from {nasdaq_start_date} to {today}\")\n",
    "\n",
    "        # Fetch stock data for normal tickers\n",
    "        try:\n",
    "            stock_data = yf.download(TICKERS, start=start_date, end=today, group_by='ticker', threads=5)\n",
    "            logger.info(f\"Stock data downloaded: {len(stock_data)} rows\")\n",
    "        except Exception as download_error:\n",
    "            logger.error(f\"Failed to download stock data: {download_error}\")\n",
    "            return\n",
    "        \n",
    "        # Fetch NASDAQ Composite Index (^IXIC) data\n",
    "        try:\n",
    "            nasdaq_data = yf.download(NASDAQ_TICKER, start=nasdaq_start_date, end=today)\n",
    "            logger.info(f\"NASDAQ data downloaded: {nasdaq_data.shape} rows and columns\")\n",
    "        except Exception as nasdaq_error:\n",
    "            logger.error(f\"Failed to download NASDAQ data: {nasdaq_error}\")\n",
    "            return\n",
    "\n",
    "        # Debug: Print column names before fixing\n",
    "        print(\"\\nNASDAQ Column Names BEFORE FIX:\", nasdaq_data.columns)\n",
    "\n",
    "        # 🛠 FIX: Flatten NASDAQ MultiIndex Columns\n",
    "        if isinstance(nasdaq_data.columns, pd.MultiIndex):\n",
    "            nasdaq_data.columns = [col[0] for col in nasdaq_data.columns]\n",
    "        nasdaq_data = nasdaq_data.reset_index()  # Convert Date index into a column\n",
    "\n",
    "        # Detect correct column names dynamically\n",
    "        column_map = {\n",
    "            \"Close\": None,\n",
    "            \"Open\": None,\n",
    "            \"High\": None,\n",
    "            \"Low\": None,\n",
    "            \"Volume\": None\n",
    "        }\n",
    "\n",
    "        for col in nasdaq_data.columns:\n",
    "            for key in column_map.keys():\n",
    "                if key in col:\n",
    "                    column_map[key] = col\n",
    "\n",
    "        # Rename columns using detected names\n",
    "        nasdaq_data = nasdaq_data.rename(columns=column_map)\n",
    "\n",
    "        # Debug: Print final column names after renaming\n",
    "        print(\"\\nNASDAQ Column Names FINAL:\", nasdaq_data.columns)\n",
    "\n",
    "        formatted_data = []\n",
    "\n",
    "        # Process normal tickers\n",
    "        for ticker in TICKERS:\n",
    "            try:\n",
    "                if ticker in stock_data.columns.get_level_values(0):\n",
    "                    ticker_data = stock_data[ticker].iloc[-1]  # Get latest data\n",
    "                    \n",
    "                    if pd.notna(ticker_data['Close']):\n",
    "                        # Find previous close safely\n",
    "                        previous_close = stock_data[ticker]['Close'].shift(1).iloc[-1]\n",
    "                        percent_difference = None\n",
    "                        \n",
    "                        if pd.notna(previous_close):\n",
    "                            percent_difference = ((ticker_data['Close'] - previous_close) / previous_close)\n",
    "\n",
    "                        formatted_data.append({\n",
    "                            \"Date\": today.strftime('%Y-%m-%d'),\n",
    "                            \"Ticker\": ticker,\n",
    "                            \"Close\": ticker_data['Close'],\n",
    "                            \"Volume\": ticker_data['Volume'],\n",
    "                            \"High\": ticker_data['High'],\n",
    "                            \"Low\": ticker_data['Low'],\n",
    "                            \"Open\": ticker_data['Open'],\n",
    "                            \"Percent_Difference\": percent_difference\n",
    "                        })\n",
    "            except Exception as ticker_error:\n",
    "                logger.error(f\"Error processing {ticker}: {ticker_error}\")\n",
    "                continue\n",
    "\n",
    "        # Process NASDAQ Data\n",
    "        for _, row in nasdaq_data.iterrows():\n",
    "            try:\n",
    "                # Compute percent difference safely\n",
    "                previous_close = nasdaq_data[\"Close\"].shift(1).iloc[-1] if len(nasdaq_data) > 1 else None\n",
    "                percent_difference = None\n",
    "\n",
    "                if pd.notna(previous_close):\n",
    "                    percent_difference = ((row[\"Close\"] - previous_close) / previous_close)\n",
    "\n",
    "                formatted_data.append({\n",
    "                    \"Date\": row[\"Date\"].strftime('%Y-%m-%d'),\n",
    "                    \"Ticker\": NASDAQ_TICKER,\n",
    "                    \"Close\": row[\"Close\"],\n",
    "                    \"Volume\": row[\"Volume\"] if \"Volume\" in nasdaq_data.columns else None,\n",
    "                    \"High\": row[\"High\"] if \"High\" in nasdaq_data.columns else None,\n",
    "                    \"Low\": row[\"Low\"] if \"Low\" in nasdaq_data.columns else None,\n",
    "                    \"Open\": row[\"Open\"] if \"Open\" in nasdaq_data.columns else None,\n",
    "                    \"Percent_Difference\": percent_difference\n",
    "                })\n",
    "            except Exception as nasdaq_error:\n",
    "                logger.error(f\"Error processing NASDAQ (^IXIC): {nasdaq_error}\")\n",
    "                continue\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        reformatted_data = pd.DataFrame(formatted_data)\n",
    "\n",
    "        # Save to CSV for debugging\n",
    "        reformatted_data.to_csv(\"output.csv\", index=False)\n",
    "        logger.info(\"Saved output.csv for verification.\")\n",
    "\n",
    "    except Exception as general_error:\n",
    "        logger.error(f\"Unexpected error: {general_error}\")\n",
    "\n",
    "# Run the function locally\n",
    "extract_stock_close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\BryceDaniel\\OneDrive\n",
      "[nltk_data]     - Lincoln Telephone\n",
      "[nltk_data]     Company\\MSBA\\GitHub\\TrendSense\\Market\n",
      "[nltk_data]     News\\Market_News_Yahoo_Extract_Function\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data successfully saved to market_news.csv\n"
     ]
    }
   ],
   "source": [
    "# Yahoo Extract with date restriction \n",
    "\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "# Explicitly set the nltk_data path\n",
    "nltk_data_path = r\"C:\\Users\\BryceDaniel\\OneDrive - Lincoln Telephone Company\\MSBA\\GitHub\\TrendSense\\Market News\\Market_News_Yahoo_Extract_Function\\nltk_data\"\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "# Ensure 'punkt' is downloaded into the correct folder\n",
    "nltk.download('punkt', download_dir=nltk_data_path)\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def calculate_sentiment(text):\n",
    "    try:\n",
    "        analysis = TextBlob(text)\n",
    "        return analysis.sentiment.polarity\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Sentiment analysis failed: {e}\")\n",
    "        return 0\n",
    "\n",
    "def label_sentiment(score):\n",
    "    if score > 0.35:\n",
    "        return \"Bullish\"\n",
    "    elif 0.15 < score <= 0.35:\n",
    "        return \"Somewhat-Bullish\"\n",
    "    elif -0.15 <= score <= 0.15:\n",
    "        return \"Neutral\"\n",
    "    elif -0.35 <= score < -0.15:\n",
    "        return \"Somewhat-Bearish\"\n",
    "    else:\n",
    "        return \"Bearish\"\n",
    "\n",
    "def get_market_news(tickers, days_back=2):\n",
    "    all_news = []\n",
    "    today = datetime.now().date()\n",
    "    cutoff_date = today - timedelta(days=days_back)\n",
    "\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        try:\n",
    "            news = stock.news\n",
    "            for item in news:\n",
    "                try:\n",
    "                    # Extract publish timestamp and date\n",
    "                    publish_timestamp = item.get('providerPublishTime', 0)\n",
    "                    publish_date = datetime.fromtimestamp(publish_timestamp).date()\n",
    "\n",
    "                    # Only process news within the desired date range\n",
    "                    if publish_date >= cutoff_date:\n",
    "                        title = item.get('title', '')\n",
    "                        sentiment_score = calculate_sentiment(title)\n",
    "                        sentiment_label = label_sentiment(sentiment_score)\n",
    "\n",
    "                        news_item = {\n",
    "                            'ticker': ticker,\n",
    "                            'title': title,\n",
    "                            'summary': title,  # Replicate title in the summary column\n",
    "                            'publisher': item.get('publisher', ''),\n",
    "                            'link': item.get('link', ''),\n",
    "                            'publish_date': datetime.fromtimestamp(publish_timestamp),\n",
    "                            'type': item.get('type', ''),\n",
    "                            'related_tickers': ', '.join(item.get('relatedTickers', [])),\n",
    "                            'source': 'yahoo',\n",
    "                            'overall_sentiment_score': sentiment_score,\n",
    "                            'overall_sentiment_label': sentiment_label,\n",
    "                        }\n",
    "                        all_news.append(news_item)\n",
    "                except Exception as news_item_error:\n",
    "                    print(f\"[ERROR] Error processing news item: {news_item_error}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Error retrieving news for {ticker}: {str(e)}\")\n",
    "    return pd.DataFrame(all_news)\n",
    "\n",
    "def save_to_csv(df, filename):\n",
    "    try:\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"[INFO] Data successfully saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to save data to CSV: {e}\")\n",
    "\n",
    "def fetch_and_save_market_news():\n",
    "    indices = ['^IXIC', '^DJI', '^RUT', '^GSPC']\n",
    "    market_news = get_market_news(tickers=indices)\n",
    "    if not market_news.empty:\n",
    "        market_news['category'] = 'General'\n",
    "\n",
    "    tech_stocks = [\n",
    "        'AAPL', 'GOOGL', 'MSFT', 'ASTS', 'PTON', 'GSAT', 'PLTR', 'SMR', 'ACHR',\n",
    "        'BWXT', 'ARBK', 'AMD', 'NVDA', 'BTC', 'GME', 'MU', 'TSLA', 'NFLX', 'ZG',\n",
    "        'AVGO', 'SMCI', 'GLW', 'HAL', 'LMT', 'AMZN', 'CRM', 'NOW', 'CHTR', 'TDS', 'META','RGTI','QUBT',\n",
    "        'LX', 'OKLO', 'PSIX', 'QFIN', 'RTX', 'TWLO'\n",
    "    ]\n",
    "    tech_news = get_market_news(tickers=tech_stocks)\n",
    "    if not tech_news.empty:\n",
    "        tech_news['category'] = 'Tech'\n",
    "\n",
    "    combined_news = pd.concat([market_news, tech_news], ignore_index=True)\n",
    "\n",
    "    if not combined_news.empty:\n",
    "        save_to_csv(combined_news, \"market_news.csv\")\n",
    "    else:\n",
    "        print(\"[INFO] No news data to save.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_and_save_market_news()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_gbq\n",
      "  Downloading pandas_gbq-0.27.0-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas_gbq) (75.2.0)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas_gbq) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas_gbq) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas_gbq) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=4.0.0 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas_gbq) (17.0.0)\n",
      "Collecting pydata-google-auth>=1.5.0 (from pandas_gbq)\n",
      "  Downloading pydata_google_auth-1.9.1-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.10.2 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas_gbq) (2.21.0)\n",
      "Requirement already satisfied: google-auth>=2.13.0 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas_gbq) (2.35.0)\n",
      "Collecting google-auth-oauthlib>=0.7.0 (from pandas_gbq)\n",
      "  Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=3.4.2 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas_gbq) (3.26.0)\n",
      "Requirement already satisfied: packaging>=22.0.0 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas_gbq) (24.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.65.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (5.28.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.24.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.13.0->pandas_gbq) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.13.0->pandas_gbq) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.13.0->pandas_gbq) (4.9)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib>=0.7.0->pandas_gbq)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas_gbq) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas_gbq) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas_gbq) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->pandas_gbq) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->pandas_gbq) (2024.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas_gbq) (1.67.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas_gbq) (1.67.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-resumable-media<3.0dev,>=2.0.0->google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas_gbq) (1.6.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas_gbq) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas_gbq) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2024.8.30)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas_gbq)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading pandas_gbq-0.27.0-py2.py3-none-any.whl (37 kB)\n",
      "Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading pydata_google_auth-1.9.1-py2.py3-none-any.whl (15 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, google-auth-oauthlib, pydata-google-auth, pandas_gbq\n",
      "Successfully installed google-auth-oauthlib-1.2.1 oauthlib-3.2.2 pandas_gbq-0.27.0 pydata-google-auth-1.9.1 requests-oauthlib-2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas_gbq\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yahoo Finance Targets:\n",
      "Recommendations:\n",
      "  period  strongBuy  buy  hold  sell  strongSell\n",
      "0     0m          2    3     0     0           0\n",
      "1    -1m          2    3     0     0           0\n",
      "2    -2m          2    3     0     0           0\n",
      "3    -3m          2    3     0     0           0\n",
      "\n",
      "Price Targets:\n",
      "Current Price: 25.645\n",
      "Target High Price: 53.0\n",
      "Target Low Price: 15.0\n",
      "Target Mean Price: 35.94\n",
      "Target Median Price: 36.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import yfinance as yf\n",
    "\n",
    "class StockPriceTargetRetriever:\n",
    "    def __init__(self, api_key=None):\n",
    "        \"\"\"\n",
    "        Initialize the Stock Price Target Retriever\n",
    "        \n",
    "        :param api_key: API key for paid services (optional)\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "    \n",
    "    def get_yahoo_finance_target(self, symbol):\n",
    "        \"\"\"\n",
    "        Retrieve price targets and recommendations from Yahoo Finance\n",
    "        \n",
    "        :param symbol: Stock ticker symbol\n",
    "        :return: Dictionary with recommendations and price targets\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Fetch the stock information\n",
    "            stock = yf.Ticker(symbol)\n",
    "            \n",
    "            # Fetch analyst recommendations\n",
    "            recommendations = stock.recommendations\n",
    "            \n",
    "            # Fetch analyst price targets\n",
    "            info = stock.info\n",
    "            \n",
    "            # Extract price target information from stock info\n",
    "            price_targets = {\n",
    "                'current_price': info.get('currentPrice'),\n",
    "                'target_high_price': info.get('targetHighPrice'),\n",
    "                'target_low_price': info.get('targetLowPrice'),\n",
    "                'target_mean_price': info.get('targetMeanPrice'),\n",
    "                'target_median_price': info.get('targetMedianPrice')\n",
    "            }\n",
    "            \n",
    "            return {\n",
    "                'recommendations': recommendations,\n",
    "                'price_targets': price_targets\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching Yahoo Finance data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_alpha_vantage_overview(self, symbol):\n",
    "        \"\"\"\n",
    "        Retrieve stock overview from Alpha Vantage\n",
    "        \n",
    "        :param symbol: Stock ticker symbol\n",
    "        :return: Dictionary of stock overview data\n",
    "        \"\"\"\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"Alpha Vantage requires an API key\")\n",
    "        \n",
    "        url = f'https://www.alphavantage.co/query?function=OVERVIEW&symbol={symbol}&apikey={self.api_key}'\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching data from Alpha Vantage: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_financial_modeling_prep_target(self, symbol):\n",
    "        \"\"\"\n",
    "        Retrieve price targets from Financial Modeling Prep\n",
    "        \n",
    "        :param symbol: Stock ticker symbol\n",
    "        :return: List of price target data\n",
    "        \"\"\"\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"Financial Modeling Prep requires an API key\")\n",
    "        \n",
    "        url = f'https://financialmodelingprep.com/api/v3/price-target?symbol={symbol}&apikey={self.api_key}'\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching data from Financial Modeling Prep: {e}\")\n",
    "            return None\n",
    "\n",
    "def main():\n",
    "    # Initialize the retriever\n",
    "    retriever = StockPriceTargetRetriever()\n",
    "    \n",
    "    # Retrieve price targets for Apple (AAPL)\n",
    "    symbol = 'ASTS'\n",
    "    \n",
    "    # Yahoo Finance (completely free)\n",
    "    yahoo_targets = retriever.get_yahoo_finance_target(symbol)\n",
    "    \n",
    "    # Print results with error handling\n",
    "    if yahoo_targets:\n",
    "        print(\"Yahoo Finance Targets:\")\n",
    "        print(\"Recommendations:\")\n",
    "        print(yahoo_targets.get('recommendations', 'No recommendations available'))\n",
    "        print(\"\\nPrice Targets:\")\n",
    "        price_targets = yahoo_targets.get('price_targets', {})\n",
    "        for key, value in price_targets.items():\n",
    "            print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve stock information.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# Important Notes:\n",
    "# 1. This script requires yfinance library\n",
    "# 2. Install dependencies: pip install yfinance requests\n",
    "# 3. Be aware of potential rate limits or changes in Yahoo Finance's structure\n",
    "\n",
    "# Troubleshooting:\n",
    "# - Ensure you have the latest version of yfinance\n",
    "# - Some stock symbols might not have complete information\n",
    "# - Network connectivity can affect data retrieval\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent successfully.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BryceDaniel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Skipping non-story type: VIDEO\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/p-500-closes-record-high-213627406.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/p-500-closes-record-high-213627406.html: name 'requests' is not defined\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/live/stock-market-today-sp-500-clinches-first-record-close-of-2025-dow-pops-after-trump-takes-spotlight-at-davos-210311077.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/live/stock-market-today-sp-500-clinches-first-record-close-of-2025-dow-pops-after-trump-takes-spotlight-at-davos-210311077.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-comments-leave-equity-markets-205020322.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-comments-leave-equity-markets-205020322.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-comments-leave-equities-mixed-185441569.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-comments-leave-equities-mixed-185441569.html: name 'requests' is not defined\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/live/stock-market-today-sp-500-clinches-first-record-close-of-2025-dow-pops-after-trump-takes-spotlight-at-davos-210311077.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/live/stock-market-today-sp-500-clinches-first-record-close-of-2025-dow-pops-after-trump-takes-spotlight-at-davos-210311077.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/top-cryptocurrencies-fall-bitcoin-drops-210004065.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/top-cryptocurrencies-fall-bitcoin-drops-210004065.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-comments-leave-equity-markets-205020322.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-comments-leave-equity-markets-205020322.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/us-equity-indexes-mixed-technology-182320372.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/us-equity-indexes-mixed-technology-182320372.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/major-us-stock-indexes-fared-211814315.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/initial-claims-higher-estimates-155300236.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/initial-claims-higher-estimates-155300236.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/pre-markets-seek-direction-warmer-153200988.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/pre-markets-seek-direction-warmer-153200988.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/vanguard-russell-2000-value-etf-112008096.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/vanguard-russell-2000-value-etf-112008096.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/asian-shares-ride-wall-street-224004019.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/asian-shares-ride-wall-street-224004019.html: name 'requests' is not defined\n",
      "[INFO] Skipping non-story type: VIDEO\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/3eaea4ff-1238-3bd0-84c5-ef7aedf91b70/why-prologis-stock-was-a.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/3eaea4ff-1238-3bd0-84c5-ef7aedf91b70/why-prologis-stock-was-a.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/brf-brfs-stock-falls-amid-230024316.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/brf-brfs-stock-falls-amid-230024316.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/cloudflare-net-rises-higher-market-230024297.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/cloudflare-net-rises-higher-market-230024297.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/monday-com-mndy-stock-drops-230023207.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/monday-com-mndy-stock-drops-230023207.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/cadence-design-systems-cdns-outperforms-230022774.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/cadence-design-systems-cdns-outperforms-230022774.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/gold-fields-gfi-gains-lags-230021576.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/gold-fields-gfi-gains-lags-230021576.html: name 'requests' is not defined\n",
      "[INFO] Fetched 21 news articles.\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-224128923.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-224128923.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/d6ad7585-fc9b-3f5f-9207-11c2c3f75d3c/former-apple-executive-asks.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/d6ad7585-fc9b-3f5f-9207-11c2c3f75d3c/former-apple-executive-asks.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/apple-poised-largely-line-first-204840044.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/apple-poised-largely-line-first-204840044.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/6ec2f756-d24d-3154-a494-c4f23da4bd4f/as-apple-earnings-near%2C-more.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/6ec2f756-d24d-3154-a494-c4f23da4bd4f/as-apple-earnings-near%2C-more.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/apple-inc-aapl-among-billionaire-195410392.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/apple-inc-aapl-among-billionaire-195410392.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-194817735.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-194817735.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/india-urges-apple-google-host-185435371.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/india-urges-apple-google-host-185435371.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-224128923.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-224128923.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/aed87e43-725f-39b2-8531-1c08e0b941e7/ibd-50-stock-in-huge-demand-%E2%80%94.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/aed87e43-725f-39b2-8531-1c08e0b941e7/ibd-50-stock-in-huge-demand-%E2%80%94.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/alphabet-inc-googl-best-socially-202310113.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/alphabet-inc-googl-best-socially-202310113.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-194817735.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/epic-games-takes-google-apple-194817735.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/india-urges-apple-google-host-185435371.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/india-urges-apple-google-host-185435371.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/0df94b1f-418c-3bdb-9d48-4ec50838622f/apple-2025-outlook%3A-ai-gets.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/0df94b1f-418c-3bdb-9d48-4ec50838622f/apple-2025-outlook%3A-ai-gets.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/d30567e5-9a57-37bc-a44c-fc2bda988228/researchers-just-stumped-ai.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/d30567e5-9a57-37bc-a44c-fc2bda988228/researchers-just-stumped-ai.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/tevogen-bio-highlights-future-ai-005300691.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/tevogen-bio-highlights-future-ai-005300691.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/trump-opens-a-divide-between-us-and-eu-over-big-tech-213413056.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/sector-tech-stocks-edge-lower-205709720.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/sector-tech-stocks-edge-lower-205709720.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/sector-tech-204124549.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/sector-tech-204124549.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/hp-stockpiling-computers-ahead-of-potential-trump-tariffs-ceo-203002131.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/hp-stockpiling-computers-ahead-of-potential-trump-tariffs-ceo-203002131.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/microsoft-corporation-msft-among-billionaire-195046386.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/microsoft-corporation-msft-among-billionaire-195046386.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/m/5dd00a9b-8305-3862-b01d-ed9edac80eb4/microsoft-stock-approaches.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/m/5dd00a9b-8305-3862-b01d-ed9edac80eb4/microsoft-stock-approaches.html: name 'requests' is not defined\n",
      "[ERROR] Newspaper3k failed for https://finance.yahoo.com/news/market-chatter-microsoft-train-1-193338908.html: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\BryceDaniel/nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\BryceDaniel\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "    - 'c:\\\\Users\\\\BryceDaniel\\\\OneDrive - Lincoln Telephone Company\\\\MSBA\\\\GitHub\\\\TrendSense\\\\nltk_data'\n",
      "**********************************************************************\n",
      ". Falling back to BeautifulSoup.\n",
      "[ERROR] BeautifulSoup also failed for https://finance.yahoo.com/news/market-chatter-microsoft-train-1-193338908.html: name 'requests' is not defined\n",
      "[INFO] Fetched 24 news articles.\n",
      "[INFO] News data saved locally at: market_news\\market_news_20250124_100549.csv\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "\n",
    "# Ensure the required NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "def fetch_article_summary(link):\n",
    "    \"\"\"\n",
    "    Fetch and summarize the article content from a URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use Newspaper3k with headers\n",
    "        article = Article(link)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        return article.summary\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Newspaper3k failed for {link}: {str(e)}. Falling back to BeautifulSoup.\")\n",
    "\n",
    "        # Fallback to BeautifulSoup\n",
    "        try:\n",
    "            response = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            paragraphs = soup.find_all(\"p\")\n",
    "            content = \" \".join([p.get_text() for p in paragraphs])\n",
    "            return content[:500] + \"...\" if len(content) > 500 else content\n",
    "        except Exception as bs_error:\n",
    "            print(f\"[ERROR] BeautifulSoup also failed for {link}: {str(bs_error)}\")\n",
    "            return \"No summary available.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_market_news(tickers):\n",
    "    \"\"\"\n",
    "    Fetch market news for the current day, capturing all available fields and generating summaries.\n",
    "    Only processes news items with 'type' set to 'story'.\n",
    "    \"\"\"\n",
    "    all_news = []\n",
    "    today = datetime.now().date()\n",
    "    one_day_ago = today - timedelta(days=1)\n",
    "\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "\n",
    "        try:\n",
    "            news = stock.news\n",
    "            for item in news:\n",
    "                try:\n",
    "                    publish_timestamp = item.get('providerPublishTime', 0)\n",
    "                    publish_date = datetime.fromtimestamp(publish_timestamp).date()\n",
    "\n",
    "                    # Filter news to include only today's and yesterday's articles\n",
    "                    if publish_date >= one_day_ago:\n",
    "                        # Only summarize articles with type 'story'\n",
    "                        if item.get('type', '').lower() == 'story':\n",
    "                            link = item.get('link', '')\n",
    "                            summary = fetch_article_summary(link) if link else \"No summary available.\"\n",
    "\n",
    "                            news_item = {\n",
    "                                'ticker': ticker,\n",
    "                                'title': item.get('title', ''),\n",
    "                                'publisher': item.get('publisher', ''),\n",
    "                                'link': link,\n",
    "                                'publish_date': datetime.fromtimestamp(publish_timestamp),\n",
    "                                'summary': summary,  # Include the generated summary\n",
    "                                'type': item.get('type', ''),  # Original type from Yahoo API\n",
    "                                'related_tickers': ', '.join(item.get('relatedTickers', [])),  # Comma-separated related tickers\n",
    "                            }\n",
    "                            all_news.append(news_item)\n",
    "                        else:\n",
    "                            print(f\"[INFO] Skipping non-story type: {item.get('type', '')}\")\n",
    "                except Exception as news_item_error:\n",
    "                    print(f\"[ERROR] Error processing news item: {news_item_error}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Error retrieving news for {ticker}: {str(e)}\")\n",
    "\n",
    "    print(f\"[INFO] Fetched {len(all_news)} news articles.\")\n",
    "    return pd.DataFrame(all_news)\n",
    "\n",
    "\n",
    "def save_to_csv(df, output_dir=\"market_news\"):\n",
    "    \"\"\"\n",
    "    Save processed news data to a CSV file locally.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if df.empty:\n",
    "            print(\"[INFO] No news data to save.\")\n",
    "            return None\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filename = f\"market_news_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        df.to_csv(filepath, index=False, encoding=\"utf-8\")\n",
    "        print(f\"[INFO] News data saved locally at: {filepath}\")\n",
    "        return filepath\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to save CSV: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function for fetching and saving market news locally.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch general market news\n",
    "        indices = ['^IXIC', '^DJI', '^RUT', '^GSPC']\n",
    "        market_news = get_market_news(tickers=indices)\n",
    "        if not market_news.empty:\n",
    "            market_news['category'] = 'General'  # Add category for general market\n",
    "\n",
    "        # Fetch tech stock news\n",
    "        tech_stocks = ['AAPL', 'GOOGL', 'MSFT']\n",
    "        tech_news = get_market_news(tickers=tech_stocks)\n",
    "        if not tech_news.empty:\n",
    "            tech_news['category'] = 'Tech'  # Add category for tech stocks\n",
    "\n",
    "        # Combine news\n",
    "        combined_news = pd.concat([market_news, tech_news], ignore_index=True)\n",
    "\n",
    "        # Save to CSV locally\n",
    "        if not combined_news.empty:\n",
    "            save_to_csv(combined_news)\n",
    "        else:\n",
    "            print(\"[INFO] No news data to save.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error in main function: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
