{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "\n",
    "# Replace with your NewsAPI key\n",
    "api_key = 'afc3fe9ac08745439bf521cb5b974fbc'\n",
    "\n",
    "# Initialize sentiment analysis tools\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "bert_sentiment = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# List of tickers to search news for\n",
    "tickers = [\n",
    "    'AAPL', 'GOOGL', 'MSFT', 'ASTS', 'PTON', 'GSAT', 'PLTR', 'SMR', 'ACHR',\n",
    "    'BWXT', 'ARBK', 'AMD', 'NVDA', 'GME', 'MU', 'TSLA', 'NFLX', 'ZG',\n",
    "    'AVGO', 'SMCI', 'GLW', 'HAL', 'LMT', 'AMZN', 'CRM', 'NOW', 'CHTR', 'TDS', 'META'\n",
    "]\n",
    "\n",
    "# Get today's date in ISO format\n",
    "today = datetime.utcnow().strftime('%Y-%m-%d')\n",
    "\n",
    "# Functions for sentiment analysis\n",
    "def vader_sentiment(text):\n",
    "    if text:\n",
    "        return vader_analyzer.polarity_scores(text)['compound']\n",
    "    return 0\n",
    "\n",
    "def textblob_sentiment(text):\n",
    "    if text:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    return 0\n",
    "\n",
    "def bert_sentiment_analysis(text):\n",
    "    if text:\n",
    "        result = bert_sentiment(text)[0]\n",
    "        return result['label'], result['score']  # Returns sentiment label and confidence\n",
    "    return \"NEUTRAL\", 0.0\n",
    "\n",
    "def bert_to_vader_scale(label, confidence):\n",
    "    label_to_score = {\n",
    "        \"1 star\": -1.0,\n",
    "        \"2 stars\": -0.5,\n",
    "        \"3 stars\": 0.0,\n",
    "        \"4 stars\": 0.5,\n",
    "        \"5 stars\": 1.0\n",
    "    }\n",
    "    return label_to_score.get(label, 0.0) * confidence\n",
    "\n",
    "# Function to fetch market news for the current day\n",
    "def get_market_news(ticker):\n",
    "    url = (\n",
    "        f'https://newsapi.org/v2/everything?q={ticker}&from={today}&to={today}&sortBy=publishedAt&apiKey={api_key}'\n",
    "    )\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('articles', [])\n",
    "    elif response.status_code == 429:\n",
    "        print(f\"Rate limit exceeded for {ticker}, retrying after delay...\")\n",
    "        time.sleep(5)\n",
    "        return []\n",
    "    else:\n",
    "        print(f\"Error fetching data for {ticker}: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Save data in the required schema\n",
    "def save_to_csv(news_data, filename=\"news_data_today.csv\"):\n",
    "    df = pd.DataFrame(news_data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Fetch and process news for all tickers\n",
    "all_news = []\n",
    "for ticker in tickers:\n",
    "    print(f\"Fetching news for {ticker}...\")\n",
    "    articles = get_market_news(ticker)\n",
    "    \n",
    "    for article in articles:\n",
    "        title = article.get('title', '')\n",
    "        summary = article.get('description', '')\n",
    "        \n",
    "        # Sentiment analysis\n",
    "        headline_vader_sentiment = vader_sentiment(title)\n",
    "        summary_textblob_sentiment = textblob_sentiment(summary)\n",
    "        summary_vader_sentiment = vader_sentiment(summary)\n",
    "        summary_bert_sentiment, bert_confidence = bert_sentiment_analysis(summary)\n",
    "        summary_bert_vader_scaled = bert_to_vader_scale(summary_bert_sentiment, bert_confidence)\n",
    "        \n",
    "        # Article schema\n",
    "        news_entry = {\n",
    "            'ticker': ticker,\n",
    "            'title': title,\n",
    "            'headline_vader_sentiment': headline_vader_sentiment,\n",
    "            'summary': summary,\n",
    "            'summary_textblob_sentiment': summary_textblob_sentiment,\n",
    "            'summary_vader_sentiment': summary_vader_sentiment,\n",
    "            'summary_bert_sentiment': summary_bert_sentiment,\n",
    "            'bert_confidence': bert_confidence,\n",
    "            'summary_bert_vader_scaled': summary_bert_vader_scaled,\n",
    "            'publisher': article.get('source', {}).get('name', ''),\n",
    "            'link': article.get('url', ''),\n",
    "            'publish_date': article.get('publishedAt', ''),\n",
    "            'type': 'general',  # Default value\n",
    "            'related_tickers': '',  # Default empty\n",
    "            'source': 'NewsAPI',  # Identify source\n",
    "        }\n",
    "        all_news.append(news_entry)\n",
    "    \n",
    "    # Avoid rate limiting\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save the formatted data to a CSV file\n",
    "if all_news:\n",
    "    save_to_csv(all_news)\n",
    "else:\n",
    "    print(\"No news data available.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news articles...\n",
      "Error fetching news for AAPL: {'status': 'error', 'code': 'rateLimited', 'message': 'You have made too many requests recently. Developer accounts are limited to 100 requests over a 24 hour period (50 requests available every 12 hours). Please upgrade to a paid plan if you need more requests.'}\n",
      "No articles found. Check your API key, date range, or network connection.\n",
      "Processing articles...\n",
      "DataFrame columns: []\n",
      "Performing sentiment analysis...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Description'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 85\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Add sentiment analysis\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming sentiment analysis...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDescription\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(textblob_sentiment)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[0;32m     88\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarket_news.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\BryceDaniel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\BryceDaniel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Description'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from textblob import TextBlob  # For sentiment analysis\n",
    "from newsapi.newsapi_client import NewsApiClient  # Correct import\n",
    "\n",
    "# Replace this with your NewsAPI key\n",
    "NEWS_API_KEY = 'afc3fe9ac08745439bf521cb5b974fbc'\n",
    "\n",
    "# Initialize NewsAPI client correctly\n",
    "newsapi = NewsApiClient(api_key=NEWS_API_KEY)\n",
    "\n",
    "# List of tickers to fetch news for\n",
    "tickers = [\n",
    "    'AAPL'\n",
    "]\n",
    "\n",
    "# Get today's and yesterday's dates\n",
    "today = datetime.now()\n",
    "yesterday = today - timedelta(days=1)\n",
    "\n",
    "# Format dates for NewsAPI\n",
    "today_str = today.strftime('%Y-%m-%d')\n",
    "yesterday_str = yesterday.strftime('%Y-%m-%d')\n",
    "\n",
    "def get_market_news(tickers, from_date, to_date):\n",
    "    \"\"\"\n",
    "    Fetch market news for specified tickers and date range.\n",
    "    \"\"\"\n",
    "    all_articles = []\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            articles = newsapi.get_everything(\n",
    "                q=ticker,\n",
    "                from_param=from_date,\n",
    "                to=to_date,\n",
    "                language='en',\n",
    "                sort_by='relevancy',\n",
    "                page_size=100\n",
    "            )\n",
    "            print(f\"Total articles found for {ticker}: {len(articles['articles'])}\")\n",
    "            \n",
    "            for article in articles['articles']:\n",
    "                all_articles.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Source': article['source']['name'],\n",
    "                    'Author': article.get('author', 'N/A'),\n",
    "                    'Title': article['title'],\n",
    "                    'Description': article.get('description', article.get('title', '')),\n",
    "                    'URL': article['url'],\n",
    "                    'Published At': article['publishedAt']\n",
    "                })\n",
    "            # To avoid hitting API rate limits\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching news for {ticker}: {e}\")\n",
    "    return all_articles\n",
    "\n",
    "def textblob_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyze sentiment using TextBlob.\n",
    "    \"\"\"\n",
    "    if text:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    return 0  # Return 0 instead of None\n",
    "\n",
    "# Fetch news articles\n",
    "print(\"Fetching news articles...\")\n",
    "articles = get_market_news(tickers, yesterday_str, today_str)\n",
    "\n",
    "# Check if articles were fetched\n",
    "if not articles:\n",
    "    print(\"No articles found. Check your API key, date range, or network connection.\")\n",
    "    exit()\n",
    "\n",
    "# Convert articles to DataFrame\n",
    "print(\"Processing articles...\")\n",
    "df = pd.DataFrame(articles)\n",
    "\n",
    "# Print columns to verify\n",
    "print(\"DataFrame columns:\", list(df.columns))\n",
    "\n",
    "# Add sentiment analysis\n",
    "print(\"Performing sentiment analysis...\")\n",
    "df['Sentiment'] = df['Description'].apply(textblob_sentiment)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'market_news.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Saved news data to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newsapi-python in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from newsapi-python) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->newsapi-python) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->newsapi-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->newsapi-python) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brycedaniel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->newsapi-python) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install newsapi-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
