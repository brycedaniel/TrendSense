
Week 4Date: 2/18/2025

Progress:
This week, I began the predictive modeling phase, testing various models to determine the best fit for accurate results. Initial evaluations suggest that a combination of machine learning techniques may be the most effective approach. I also fine-tuned data preprocessing steps to improve model performance. Additionally, I addressed cloud performance inefficiencies by optimizing function execution times and resource allocation.

Problems:
Client feedback is still pending, which has delayed certain model adjustments and validation steps. Additionally, some models require further tuning to balance accuracy and efficiency, particularly in handling large datasets.

Plans:
Next week, I will finalize model selection and begin testing on unseen data to evaluate performance. I’ll also start drafting the report outlining key findings, methodology, and insights. If client feedback is received, I will incorporate any necessary changes before finalizing the results. Additionally, I will begin integrating the predictive results into my dashboard, ensuring that key metrics and insights are easily accessible and visually interpretable.

Hours:
Approximately 15 hours this week



Week 3

Date: 2/11/2025

Progress:
This week, I successfully deployed the code to Google Cloud Functions after resolving the earlier compatibility issues. All code is now running smoothly in the cloud. The AI analysis component has been integrated, and I’ve completed the final data tables for predictive results, as well as the test and train datasets. Additionally, I’ve developed a framework that allows for dynamic adjustment of key metric weights, enhancing the flexibility of the analysis.

Problems:
While deployment issues were resolved, I ran into minor performance inefficiencies in the cloud environment, which required some optimization. I’m still awaiting feedback from the client, which has delayed progress on final adjustments and validation of the results.

Plans:
Next week, I’ll start working on the predictive modeling phase to identify the model that best suits the data for accurate results. Pending client feedback, I will adjust the model parameters accordingly and prepare a draft report summarizing findings to date.

Hours:
Approximately 22 hours this week


Week 2

Date: 2/4/2025

Progress:
This week, I focused on further cleaning the data and narrowing my scope to ensure the independent variables are more manageable. All code has been developed, and I am now working on deploying it to Google Cloud Functions.

Problems:
I've encountered several issues with Google Cloud Functions, as the environment is not very forgiving. A significant amount of time has been spent troubleshooting and modifying the code to ensure compatibility. Additionally, I have not received a response from my client.

Plans:
My goal is to have all code fully operational in the cloud by the end of the week, including the integration of AI analysis. I will also develop a strategy to easily adjust weights on key metrics for greater flexibility in analysis.

Hours:
Approximately 20 hours this week


Week 1

Date: 1/20/2025

Progress:
This week, I focused on building combined datasets, cleaning and transforming the data, and creating two testing tables. One table provides a per-article breakdown, while the other aggregates data on a per-day basis from the per-article table. These tables will serve as the foundation for my predictive analysis. Additionally, I reached out to Professor Sonora for guidance but have not received a response yet.

Problems:
I encountered web scraping issues with the Google Functions setup. Although the code worked for about a month, it is no longer functioning as originally designed. Currently, I am running the code manually to gather articles from the past week. I'm also facing challenges with the analysis and modeling stages. I plan to consult John for assistance on these issues.

Plans:
My immediate goal is to refine the tables further to ensure they contain more relevant data. Initial permutation tests using sentiment analysis alone were not statistically significant. To address this, I will begin incorporating large language models (LLMs) to cross-check sentiment and explore how they can be integrated into my code.

Hours:
It was a busy week, with approximately 18 hours spent on this work.