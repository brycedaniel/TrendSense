Week 3

Date: 2/11/2025

Progress:
This week, I successfully deployed the code to Google Cloud Functions after resolving the earlier compatibility issues. All code is now running smoothly in the cloud. The AI analysis component has been integrated, and I’ve completed the final data tables for predictive results, as well as the test and train datasets. Additionally, I’ve developed a framework that allows for dynamic adjustment of key metric weights, enhancing the flexibility of the analysis.

Problems:
While deployment issues were resolved, I ran into minor performance inefficiencies in the cloud environment, which required some optimization. I’m still awaiting feedback from the client, which has delayed progress on final adjustments and validation of the results.

Plans:
Next week, I’ll start working on the predictive modeling phase to identify the model that best suits the data for accurate results. Pending client feedback, I will adjust the model parameters accordingly and prepare a draft report summarizing findings to date.

Hours:
Approximately 22 hours this week


Week 2

Date: 2/4/2025

Progress:
This week, I focused on further cleaning the data and narrowing my scope to ensure the independent variables are more manageable. All code has been developed, and I am now working on deploying it to Google Cloud Functions.

Problems:
I've encountered several issues with Google Cloud Functions, as the environment is not very forgiving. A significant amount of time has been spent troubleshooting and modifying the code to ensure compatibility. Additionally, I have not received a response from my client.

Plans:
My goal is to have all code fully operational in the cloud by the end of the week, including the integration of AI analysis. I will also develop a strategy to easily adjust weights on key metrics for greater flexibility in analysis.

Hours:
Approximately 20 hours this week


Week 1

Date: 1/20/2025

Progress:
This week, I focused on building combined datasets, cleaning and transforming the data, and creating two testing tables. One table provides a per-article breakdown, while the other aggregates data on a per-day basis from the per-article table. These tables will serve as the foundation for my predictive analysis. Additionally, I reached out to Professor Sonora for guidance but have not received a response yet.

Problems:
I encountered web scraping issues with the Google Functions setup. Although the code worked for about a month, it is no longer functioning as originally designed. Currently, I am running the code manually to gather articles from the past week. I'm also facing challenges with the analysis and modeling stages. I plan to consult John for assistance on these issues.

Plans:
My immediate goal is to refine the tables further to ensure they contain more relevant data. Initial permutation tests using sentiment analysis alone were not statistically significant. To address this, I will begin incorporating large language models (LLMs) to cross-check sentiment and explore how they can be integrated into my code.

Hours:
It was a busy week, with approximately 18 hours spent on this work.