{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 17:11:51,372 - INFO - Fetching market news\n",
      "2024-11-21 17:11:51,709 - INFO - Retrieved 50 news items\n",
      "2024-11-21 17:11:51,715 - INFO - News data successfully saved to: market_news\\market_news_20241121_171151.csv\n",
      "2024-11-21 17:11:51,716 - INFO - News data saved successfully: market_news\\market_news_20241121_171151.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                   format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_market_news(api_key, limit=10):\n",
    "    \"\"\"\n",
    "    Retrieve market news from Alpha Vantage API.\n",
    "\n",
    "    Parameters:\n",
    "    api_key (str): Alpha Vantage API key\n",
    "    limit (int): Maximum number of news items to retrieve\n",
    "\n",
    "    Returns:\n",
    "    list: List of news items\n",
    "    \"\"\"\n",
    "    base_url = 'https://www.alphavantage.co/query'\n",
    "    params = {\n",
    "        'function': 'NEWS_SENTIMENT',\n",
    "        'apikey': api_key,\n",
    "        'limit': limit\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Fetching market news\")\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        news_data = response.json()\n",
    "\n",
    "        if 'Note' in news_data:\n",
    "            logger.warning(f\"API limit message: {news_data['Note']}\")\n",
    "            return []\n",
    "\n",
    "        if 'feed' in news_data:\n",
    "            logger.info(f\"Retrieved {len(news_data['feed'])} news items\")\n",
    "            return news_data['feed']\n",
    "        else:\n",
    "            logger.warning(\"No news found in response\")\n",
    "            return []\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Request failed: {str(e)}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error occurred: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_news_items(news_items):\n",
    "    \"\"\"\n",
    "    Process news items into a structured DataFrame, including sentiment.\n",
    "\n",
    "    Parameters:\n",
    "    news_items (list): List of news items\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing structured news data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        processed_items = []\n",
    "        for item in news_items:\n",
    "            processed_item = {\n",
    "                'ticker': ', '.join([ts['ticker'] for ts in item.get('ticker_sentiment', [])]),\n",
    "                'title': item.get('title', ''),\n",
    "                'summary': item.get('summary', ''),\n",
    "                'publisher': item.get('source', ''),\n",
    "                'link': item.get('url', ''),\n",
    "                'publish_date': item.get('time_published', ''),\n",
    "                'type': item.get('topics', ''),\n",
    "                'related_tickers': ', '.join([ts['ticker'] for ts in item.get('ticker_sentiment', [])]),\n",
    "                'overall_sentiment_score': item.get('overall_sentiment_score', ''),\n",
    "                'overall_sentiment_label': item.get('overall_sentiment_label', '')\n",
    "            }\n",
    "            processed_items.append(processed_item)\n",
    "        \n",
    "        return pd.DataFrame(processed_items)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing news items: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def save_news_to_csv(df, output_dir=\"market_news\"):\n",
    "    \"\"\"\n",
    "    Save processed news data to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing news data\n",
    "    output_dir (str): Directory to save the CSV file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if df.empty:\n",
    "            logger.warning(\"No news data to save.\")\n",
    "            return None\n",
    "\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Generate filename with timestamp\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"market_news_{timestamp}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "        logger.info(f\"News data successfully saved to: {filepath}\")\n",
    "        return filepath\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving data to CSV: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to fetch, process, and save market news data locally.\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    api_key = \"YOUR_ALPHA_VANTAGE_API_KEY\"  # Replace with your API key\n",
    "\n",
    "    try:\n",
    "        # Fetch market news\n",
    "        news_items = get_market_news(api_key, limit=50)\n",
    "        if not news_items:\n",
    "            logger.warning(\"No news data retrieved.\")\n",
    "            return\n",
    "\n",
    "        # Process news items\n",
    "        news_df = process_news_items(news_items)\n",
    "\n",
    "        # Save processed news data to CSV\n",
    "        saved_file = save_news_to_csv(news_df)\n",
    "        if saved_file:\n",
    "            logger.info(f\"News data saved successfully: {saved_file}\")\n",
    "        else:\n",
    "            logger.warning(\"Failed to save news data.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main function: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 08:56:52,191 - INFO - Fetching market news\n",
      "2024-11-22 08:56:52,600 - INFO - Retrieved 50 news items\n",
      "2024-11-22 08:56:52,608 - INFO - News data successfully saved to: market_news\\market_news_20241122_085652.csv\n",
      "2024-11-22 08:56:52,609 - INFO - News data saved successfully: market_news\\market_news_20241122_085652.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                   format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_market_news(api_key, limit=10):\n",
    "    \"\"\"\n",
    "    Retrieve market news from Alpha Vantage API.\n",
    "\n",
    "    Parameters:\n",
    "    api_key (str): Alpha Vantage API key\n",
    "    limit (int): Maximum number of news items to retrieve\n",
    "\n",
    "    Returns:\n",
    "    list: List of news items\n",
    "    \"\"\"\n",
    "    base_url = 'https://www.alphavantage.co/query'\n",
    "    params = {\n",
    "        'function': 'NEWS_SENTIMENT',\n",
    "        'apikey': api_key,\n",
    "        'limit': limit\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Fetching market news\")\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        news_data = response.json()\n",
    "\n",
    "        if 'Note' in news_data:\n",
    "            logger.warning(f\"API limit message: {news_data['Note']}\")\n",
    "            return []\n",
    "\n",
    "        if 'feed' in news_data:\n",
    "            logger.info(f\"Retrieved {len(news_data['feed'])} news items\")\n",
    "            return news_data['feed']\n",
    "        else:\n",
    "            logger.warning(\"No news found in response\")\n",
    "            return []\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Request failed: {str(e)}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error occurred: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_news_items(news_items):\n",
    "    \"\"\"\n",
    "    Process news items into a structured DataFrame, including sentiment.\n",
    "\n",
    "    Parameters:\n",
    "    news_items (list): List of news items\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing structured news data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        processed_items = []\n",
    "        for item in news_items:\n",
    "            # Convert publish_date format\n",
    "            raw_date = item.get('time_published', '')\n",
    "            try:\n",
    "                formatted_date = datetime.strptime(raw_date, \"%Y%m%dT%H%M%S\").strftime(\"%m/%d/%Y %H:%M\")\n",
    "            except ValueError:\n",
    "                formatted_date = \"Invalid Date\"\n",
    "\n",
    "            processed_item = {\n",
    "                'ticker': ', '.join([ts['ticker'] for ts in item.get('ticker_sentiment', [])]),\n",
    "                'title': item.get('title', ''),\n",
    "                'summary': item.get('summary', ''),\n",
    "                'publisher': item.get('source', ''),\n",
    "                'link': item.get('url', ''),\n",
    "                'publish_date': formatted_date,\n",
    "                'type': item.get('topics', ''),\n",
    "                'related_tickers': ', '.join([ts['ticker'] for ts in item.get('ticker_sentiment', [])]),\n",
    "                'source': 'Alpha',\n",
    "                'overall_sentiment_score': item.get('overall_sentiment_score', ''),\n",
    "                'overall_sentiment_label': item.get('overall_sentiment_label', '')\n",
    "            }\n",
    "            processed_items.append(processed_item)\n",
    "        \n",
    "        # Reorder columns\n",
    "        column_order = ['ticker', 'title', 'summary', 'publisher', 'link', 'publish_date', 'type', \n",
    "                        'related_tickers', 'source', 'overall_sentiment_score', 'overall_sentiment_label']\n",
    "        return pd.DataFrame(processed_items)[column_order]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing news items: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def save_news_to_csv(df, output_dir=\"market_news\"):\n",
    "    \"\"\"\n",
    "    Save processed news data to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing news data\n",
    "    output_dir (str): Directory to save the CSV file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if df.empty:\n",
    "            logger.warning(\"No news data to save.\")\n",
    "            return None\n",
    "\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Generate filename with timestamp\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"market_news_{timestamp}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "        logger.info(f\"News data successfully saved to: {filepath}\")\n",
    "        return filepath\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving data to CSV: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to fetch, process, and save market news data locally.\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    api_key = \"YOUR_ALPHA_VANTAGE_API_KEY\"  # Replace with your API key\n",
    "\n",
    "    try:\n",
    "        # Fetch market news\n",
    "        news_items = get_market_news(api_key, limit=50)\n",
    "        if not news_items:\n",
    "            logger.warning(\"No news data retrieved.\")\n",
    "            return\n",
    "\n",
    "        # Process news items\n",
    "        news_df = process_news_items(news_items)\n",
    "\n",
    "        # Save processed news data to CSV\n",
    "        saved_file = save_news_to_csv(news_df)\n",
    "        if saved_file:\n",
    "            logger.info(f\"News data saved successfully: {saved_file}\")\n",
    "        else:\n",
    "            logger.warning(\"Failed to save news data.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main function: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 09:46:44,993 - INFO - Fetching market news\n",
      "2024-11-22 09:46:45,318 - INFO - Retrieved 50 news items for today.\n",
      "2024-11-22 09:46:45,332 - INFO - News data successfully saved to: market_news\\market_news_20241122_094645.csv\n",
      "2024-11-22 09:46:45,332 - INFO - News data saved successfully: market_news\\market_news_20241122_094645.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                   format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_market_news(api_key):\n",
    "    \"\"\"\n",
    "    Retrieve market news from Alpha Vantage API.\n",
    "    \"\"\"\n",
    "    base_url = 'https://www.alphavantage.co/query'\n",
    "    params = {\n",
    "        'function': 'NEWS_SENTIMENT',\n",
    "        'apikey': api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"Fetching market news\")\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        news_data = response.json()\n",
    "\n",
    "        if 'Note' in news_data:\n",
    "            logger.warning(f\"API limit message: {news_data['Note']}\")\n",
    "            return []\n",
    "\n",
    "        if 'feed' in news_data:\n",
    "            # Filter articles to include only today's articles\n",
    "            today = datetime.now().strftime('%Y-%m-%d')\n",
    "            filtered_news = [\n",
    "                item for item in news_data['feed'] \n",
    "                if datetime.strptime(item['time_published'], \"%Y%m%dT%H%M%S\").strftime('%Y-%m-%d') == today\n",
    "            ]\n",
    "            logger.info(f\"Retrieved {len(filtered_news)} news items for today.\")\n",
    "            return filtered_news\n",
    "        else:\n",
    "            logger.warning(\"No news found in response\")\n",
    "            return []\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Request failed: {str(e)}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error occurred: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_news_items(news_items):\n",
    "    \"\"\"\n",
    "    Process news items into a structured DataFrame, including sentiment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        processed_items = []\n",
    "        for item in news_items:\n",
    "            # Convert publish_date format\n",
    "            raw_date = item.get('time_published', '')\n",
    "            try:\n",
    "                formatted_date = datetime.strptime(raw_date, \"%Y%m%dT%H%M%S\").strftime(\"%m/%d/%Y %H:%M\")\n",
    "            except ValueError:\n",
    "                formatted_date = \"Invalid Date\"\n",
    "\n",
    "            processed_item = {\n",
    "                'ticker': ', '.join([ts['ticker'] for ts in item.get('ticker_sentiment', [])]),\n",
    "                'title': item.get('title', ''),\n",
    "                'summary': item.get('summary', ''),\n",
    "                'publisher': item.get('source', ''),\n",
    "                'link': item.get('url', ''),\n",
    "                'publish_date': formatted_date,\n",
    "                'type': item.get('topics', ''),\n",
    "                'related_tickers': ', '.join([ts['ticker'] for ts in item.get('ticker_sentiment', [])]),\n",
    "                'source': 'Alpha',\n",
    "                'overall_sentiment_score': item.get('overall_sentiment_score', ''),\n",
    "                'overall_sentiment_label': item.get('overall_sentiment_label', '')\n",
    "            }\n",
    "            processed_items.append(processed_item)\n",
    "        \n",
    "        # Reorder columns\n",
    "        column_order = ['ticker', 'title', 'summary', 'publisher', 'link', 'publish_date', 'type', \n",
    "                        'related_tickers', 'source', 'overall_sentiment_score', 'overall_sentiment_label']\n",
    "        return pd.DataFrame(processed_items)[column_order]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing news items: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def save_to_csv(df, output_dir=\"market_news\"):\n",
    "    \"\"\"\n",
    "    Save processed news data to a local CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing news data\n",
    "    output_dir (str): Directory to save the CSV file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if df.empty:\n",
    "            logger.warning(\"No news data to save.\")\n",
    "            return None\n",
    "\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Generate filename with timestamp\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"market_news_{timestamp}.csv\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "        logger.info(f\"News data successfully saved to: {filepath}\")\n",
    "        return filepath\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving data to CSV: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to fetch, process, and save market news data locally.\n",
    "    \"\"\"\n",
    "    # Replace this with your actual Alpha Vantage API key\n",
    "    api_key = \"FLGDYAANWX6EFL9P\"\n",
    "\n",
    "    try:\n",
    "        # Fetch market news\n",
    "        news_items = get_market_news(api_key)\n",
    "        if not news_items:\n",
    "            logger.warning(\"No news data retrieved.\")\n",
    "            return\n",
    "\n",
    "        # Process news items\n",
    "        news_df = process_news_items(news_items)\n",
    "\n",
    "        # Save processed news data to a local CSV file\n",
    "        saved_file = save_to_csv(news_df)\n",
    "        if saved_file:\n",
    "            logger.info(f\"News data saved successfully: {saved_file}\")\n",
    "        else:\n",
    "            logger.warning(\"Failed to save news data.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main function: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
